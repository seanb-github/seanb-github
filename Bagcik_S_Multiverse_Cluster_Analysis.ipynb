{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c19031",
   "metadata": {},
   "source": [
    "# Author: S.R.E.A Bagcik\n",
    "### Date: 26-01-2024\n",
    "### E-mail: s.r.e.a.bagcik@lumc.nl / seanbagcik@hotmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0092f",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "* [Packages](#chapter1)\n",
    "* [Data Wrangling](#chapter2)\n",
    "* [Silhouette Analysis with Euclidean Distance](#chapter3)\n",
    "* [Silhouette Analysis with Gower's Distance](#chapter4)\n",
    "* [The Gap Statistic with Euclidean Distance](#chapter5)\n",
    "    * [Plotting the Gap Statistic](#section_5_1)\n",
    "* [The Gap Statistic with Gower's Distance](#chapter6)    \n",
    "* [Stability Function: Rand & adjusted Rand Index](#chapter7)\n",
    "* [Scenario 1](#chapter8)\n",
    "* [Scenario 1: Prognostic Value & Stability Bootstrap](#chapter9)\n",
    "* [Scenario 1: SHAP Analysis](#chapter10)\n",
    "* [Grid Search Gaussian Mixture](#chapter11)\n",
    "* [Scenario 2](#chapter12)\n",
    "* [Scenario 2: Prognostic Value & Stability Bootstrap](#chapter13)\n",
    "* [Scenario 2: SHAP Analysis](#chapter14) \n",
    "* [Agreement: Pair-Confusion Matrix](#chapter15)\n",
    "* [Agreement: Contingency Table](#chapter16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d4c7f",
   "metadata": {},
   "source": [
    "## Packages <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c1e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from typing import Callable, Union\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sn\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "import gower\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.stats import sem\n",
    "from sklearn import metrics, mixture\n",
    "from sklearn.cluster import (\n",
    "    AgglomerativeClustering,\n",
    "    AffinityPropagation,\n",
    "    Birch,\n",
    "    DBSCAN,\n",
    "    KMeans,\n",
    "    MeanShift,\n",
    "    OPTICS,\n",
    "    SpectralClustering\n",
    ")\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    adjusted_mutual_info_score,\n",
    "    log_loss,\n",
    "    mutual_info_score,\n",
    "    normalized_mutual_info_score,\n",
    "    pairwise_distances,\n",
    "    roc_auc_score,\n",
    "    silhouette_samples,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.metrics.cluster import contingency_matrix, pair_confusion_matrix\n",
    "from sklearn.metrics.cluster._expected_mutual_info_fast import expected_mutual_information\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestCentroid, kneighbors_graph\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.utils import check_random_state, resample\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "593b6fff",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Bagcik_S_Multiverse_Cluster_Analysis.ipynb to html\n",
      "[NbConvertApp] Writing 830958 bytes to Bagcik_S_Multiverse_Cluster_Analysis.html\n"
     ]
    }
   ],
   "source": [
    "# Set data directory\n",
    "DATA_DIR = '/Users/seanvanbork/Desktop/multiverse_cluster_analysis'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "!jupyter nbconvert --to html --TagRemovePreprocessor.remove_cell_tags={'no'} Bagcik_S_Multiverse_Cluster_Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65e499",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12d29f1",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "DATA_DIR = '/Users/seanvanbork/Desktop/multiverse_cluster_analysis/Data'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# Read in data\n",
    "cluster_vars = pd.read_csv(os.path.join(DATA_DIR, 'OPAL/OPAL_cluster_vars.csv'))\n",
    "\n",
    "gower_matrix = pd.read_csv(os.path.join(DATA_DIR, 'OPAL/OPAL_gower_matrix.csv'))\n",
    "\n",
    "y = pd.read_csv(os.path.join(DATA_DIR, 'OPAL/OPAL_GOSE6monthEndpointDerived.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ea746",
   "metadata": {},
   "source": [
    "## Data Wrangling <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "In this code block, we dichotomize the 6-month extended Glasgow Outcome Scale (GOSE). Subsequently, we encode the ordinal categorical feature pupil score. We create dummy variables for the feature injury cause, which is non-ordinal categorical. Last, we scale our features to avoid the scale influencing the Euclidean distance in scenario 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51af3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Used in Cluster Analysis \n",
      "\n",
      "1. Subject.Age\n",
      "2. InjuryHx.GCSMotorBaselineDerived\n",
      "3. InjuryHx.GCSScoreBaselineDerived\n",
      "4. InjuryHx.PupilsBaselineDerived\n",
      "5. InjuryHx.EDComplEventHypoxia\n",
      "6. InjuryHx.EDComplEventHypotension\n",
      "7. InjuryHx.InjCause\n",
      "8. InjuryHx.MajorExtracranialInjury\n",
      "9. dim1\n",
      "10. dim2\n",
      "11. dim3\n",
      "12. dim4\n"
     ]
    }
   ],
   "source": [
    "# Dichotomize\n",
    "y_dich = (y >= 5).astype(int)\n",
    "\n",
    "# Encode \"PupilsBaselineDerived\" (Ordinal categorical)\n",
    "encoder = LabelEncoder()\n",
    "cluster_vars_encoded = cluster_vars.copy()\n",
    "cluster_vars_encoded['InjuryHx.PupilsBaselineDerived'] = encoder.fit_transform(\n",
    "    cluster_vars_encoded['InjuryHx.PupilsBaselineDerived'])\n",
    "\n",
    "# Features for reference distribution in Gap Method\n",
    "cluster_vars_gap = cluster_vars_encoded.copy()\n",
    "cluster_vars_gap['InjuryHx.InjCause'] = encoder.fit_transform(\n",
    "    cluster_vars_encoded['InjuryHx.InjCause'])\n",
    "\n",
    "# One-hot-encoding \"InjuryHx.InjCause\" (Categorical, but equal weights)\n",
    "dummy_columns = pd.get_dummies(cluster_vars_encoded['InjuryHx.InjCause'])\n",
    "cluster_vars_encoded = pd.concat(\n",
    "    [cluster_vars_encoded.drop('InjuryHx.InjCause', axis=1), dummy_columns],\n",
    "    axis=1)\n",
    "\n",
    "# Scaling the data\n",
    "columns_to_scale = [\n",
    "    'Subject.Age', 'InjuryHx.GCSMotorBaselineDerived',\n",
    "    'InjuryHx.GCSScoreBaselineDerived', 'dim1', 'dim2', 'dim3', 'dim4'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_vars_encoded[columns_to_scale])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_to_scale)\n",
    "non_scaled_columns = [\n",
    "    col for col in cluster_vars_encoded.columns if col not in columns_to_scale\n",
    "]\n",
    "\n",
    "cluster_vars_encoded_scaled = pd.concat(\n",
    "    [cluster_vars_encoded[non_scaled_columns], scaled_df], axis=1)\n",
    "\n",
    "print(\"Features Used in Cluster Analysis \\n\")\n",
    "for i, column in enumerate(cluster_vars.columns, 1):\n",
    "    print(f\"{i}. {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55adcee8",
   "metadata": {},
   "source": [
    "## AUC with Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2471a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5855859543118508\n"
     ]
    }
   ],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=3).fit_predict(\n",
    "    pd.DataFrame(cluster_vars_encoded_scaled['Subject.Age']))\n",
    "\n",
    "df = pd.DataFrame({\"y\": np.ravel(y_dich), \"labels\": np.ravel(clustering)})\n",
    "\n",
    "model = sm.formula.glm(formula=\"y ~ labels\",\n",
    "                       family=sm.families.Binomial(),\n",
    "                       data=df).fit()\n",
    "\n",
    "y_pred_apparent = model.predict(df['labels'])\n",
    "\n",
    "auc_apparent = roc_auc_score(df['y'], y_pred_apparent)\n",
    "\n",
    "print(auc_apparent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924a4da",
   "metadata": {},
   "source": [
    "## Silhouette Analysis with Euclidean Distance <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23553bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_silhouette_euclidean(algorithm, data, range_n_clusters):\n",
    "\n",
    "    max_silhouette_avg = -1\n",
    "    best_n_clusters = -1\n",
    "    silhouette_values = [\n",
    "    ]  # List to store silhouette scores for each iteration\n",
    "\n",
    "    # Iterate over range of cluster numbers\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Choose clustering algorithm\n",
    "        if algorithm == KMedoids:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  method='alternate').fit(data)\n",
    "        elif algorithm == AgglomerativeClustering:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  linkage='average').fit(data)\n",
    "        elif algorithm == SpectralClustering:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  affinity='nearest_neighbors').fit(data)\n",
    "\n",
    "        cluster_labels = clusterer.labels_\n",
    "\n",
    "        # Calculate silhouette score only if there is more than one cluster\n",
    "        if len(set(cluster_labels)) == 1:\n",
    "            silhouette_avg = 0\n",
    "        else:\n",
    "            silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "\n",
    "        # Append the silhouette score\n",
    "        silhouette_values.append(silhouette_avg)\n",
    "\n",
    "        # Update the best silhouette score\n",
    "        if silhouette_avg > max_silhouette_avg:\n",
    "            max_silhouette_avg = silhouette_avg\n",
    "            best_n_clusters = n_clusters\n",
    "\n",
    "    return best_n_clusters, silhouette_values\n",
    "\n",
    "\n",
    "algorithms = {\n",
    "    'KMedoids': KMedoids,\n",
    "    'AgglomerativeClustering': AgglomerativeClustering,\n",
    "    'SpectralClustering': SpectralClustering\n",
    "}\n",
    "\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "    best_n_clusters, silhouette_values = best_silhouette_euclidean(\n",
    "        algorithm, cluster_vars_encoded, range(2, 30))\n",
    "\n",
    "    print(\n",
    "        f\"The maximum silhouette score for {algorithm_name} is {max(silhouette_values)} for n_clusters = {best_n_clusters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2633a8",
   "metadata": {},
   "source": [
    "## Silhouette Analysis with Gower's distance <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65201c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_silhouette_gower(algorithm, distance, range_n_clusters):\n",
    "    max_silhouette_avg = -1\n",
    "    best_n_clusters = -1\n",
    "    silhouette_values = [\n",
    "    ]  # List to store silhouette scores for each iteration\n",
    "\n",
    "    # Iterate over range of cluster numbers\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Choose clustering algorithm\n",
    "        if algorithm == KMedoids:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  method='alternate',\n",
    "                                  metric='precomputed').fit(distance)\n",
    "        elif algorithm == AgglomerativeClustering:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  affinity='precomputed',\n",
    "                                  linkage='average').fit(distance)\n",
    "        elif algorithm == SpectralClustering:\n",
    "            clusterer = algorithm(n_clusters=n_clusters,\n",
    "                                  affinity='precomputed').fit(1 - distance)\n",
    "\n",
    "        cluster_labels = clusterer.labels_\n",
    "\n",
    "        # Calculate silhouette score only if there is more than one cluster\n",
    "        if len(set(cluster_labels)) == 1:\n",
    "            silhouette_avg = 0\n",
    "        else:\n",
    "            silhouette_avg = silhouette_score(distance,\n",
    "                                              cluster_labels,\n",
    "                                              metric='precomputed')\n",
    "\n",
    "        # Append silhouette score\n",
    "        silhouette_values.append(silhouette_avg)\n",
    "\n",
    "        # Update the best silhouette score\n",
    "        if silhouette_avg > max_silhouette_avg:\n",
    "            max_silhouette_avg = silhouette_avg\n",
    "            best_n_clusters = n_clusters\n",
    "\n",
    "    return best_n_clusters, silhouette_values\n",
    "\n",
    "\n",
    "algorithms = {\n",
    "    'KMedoids': KMedoids,\n",
    "    'AgglomerativeClustering': AgglomerativeClustering,\n",
    "    'SpectralClustering': SpectralClustering\n",
    "}\n",
    "\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "    best_n_clusters, silhouette_values = best_silhouette_gower(\n",
    "        algorithm, gower_matrix, range(2, 30))\n",
    "\n",
    "    print(\n",
    "        f\"The maximum silhouette score for {algorithm_name} is {max(silhouette_values)} for n_clusters = {best_n_clusters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f117e",
   "metadata": {},
   "source": [
    "## The Gap Statistic with Euclidean Distance <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07f5b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapStatistics:\n",
    "\n",
    "    def __init__(self, return_params: bool = True):\n",
    "        self.return_params = return_params\n",
    "\n",
    "    def _calculate_Wks(self, algorithm, K: int, X: pd.DataFrame) -> list:\n",
    "        dummy_columns = pd.get_dummies(X['InjuryHx.InjCause'])\n",
    "        X = pd.concat([X.drop('InjuryHx.InjCause', axis=1), dummy_columns],\n",
    "                      axis=1)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        Wks = []\n",
    "\n",
    "        if algorithm == KMedoids:\n",
    "            for k in np.arange(2, K + 1):\n",
    "                clusterer = algorithm(n_clusters=k, method='alternate').fit(X)\n",
    "                labels = clusterer.predict(X)\n",
    "                centroids = clusterer.cluster_centers_\n",
    "\n",
    "        elif algorithm == AgglomerativeClustering:\n",
    "            for k in np.arange(2, K + 1):\n",
    "                labels = algorithm(n_clusters=k,\n",
    "                                   linkage='average').fit_predict(X)\n",
    "                tmp = NearestCentroid()\n",
    "                tmp.fit(X, labels)\n",
    "                centroids = tmp.centroids_\n",
    "\n",
    "        elif algorithm == SpectralClustering:\n",
    "            for k in np.arange(2, K + 1):\n",
    "                labels = algorithm(n_clusters=k,\n",
    "                                   affinity='nearest_neighbors').fit_predict(X)\n",
    "                tmp = NearestCentroid()\n",
    "                tmp.fit(X, labels)\n",
    "                centroids = tmp.centroids_\n",
    "\n",
    "        Ds = []\n",
    "\n",
    "        for i in range(k):\n",
    "            cluster_array = np.array(X[labels == i])\n",
    "            # FORMULA (1)\n",
    "            if len(np.unique(cluster_array)) > 1:\n",
    "                d = pairwise_distances(cluster_array,\n",
    "                                       centroids[i].reshape(1, -1),\n",
    "                                       metric='euclidean')\n",
    "                Ds.append(np.sum(d))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        pooled = 1 / (2 * len(X))\n",
    "        # FORMULA (2)\n",
    "        Wk = np.sum([D * pooled for D in Ds])\n",
    "        Wks.append(Wk)\n",
    "\n",
    "        return Wks\n",
    "\n",
    "    def _simulate_Wks(self, algorithm, X: pd.DataFrame, K: int,\n",
    "                      n_iterations: int) -> [list, list]:\n",
    "        cat_columns = [3, 4, 5, 6, 7]\n",
    "        cont_columns = [0, 1, 2, 8, 9, 10, 11]\n",
    "\n",
    "        cat = X.iloc[:, cat_columns]\n",
    "        cont = X.iloc[:, cont_columns]\n",
    "\n",
    "        sampled_X = X.copy()\n",
    "\n",
    "        for col in cat.columns:\n",
    "            sampled_X[col] = np.random.randint(low=cat[col].min(),\n",
    "                                               high=cat[col].max(),\n",
    "                                               size=len(X))\n",
    "\n",
    "        for col in cont.columns:\n",
    "            sampled_X[col] = np.random.uniform(low=cont[col].min(),\n",
    "                                               high=cont[col].max(),\n",
    "                                               size=len(X))\n",
    "\n",
    "        simulated_Wks = []\n",
    "\n",
    "        for i in range(n_iterations):\n",
    "\n",
    "            Wks_star = self._calculate_Wks(algorithm=algorithm,\n",
    "                                           K=K,\n",
    "                                           X=sampled_X)\n",
    "            simulated_Wks.append(Wks_star)\n",
    "\n",
    "        sim_Wks = np.array(simulated_Wks)\n",
    "        return sim_Wks\n",
    "\n",
    "    def fit_predict(self,\n",
    "                    algorithm,\n",
    "                    K: int,\n",
    "                    X: pd.DataFrame,\n",
    "                    n_iterations: int = 5):\n",
    "        Wks = self._calculate_Wks(algorithm=algorithm, K=K, X=X)\n",
    "        sim_Wks = self._simulate_Wks(algorithm=algorithm,\n",
    "                                     K=K,\n",
    "                                     X=X,\n",
    "                                     n_iterations=n_iterations)\n",
    "\n",
    "        log_Wks = np.log(Wks)\n",
    "        log_Wks_star = np.log(sim_Wks)\n",
    "\n",
    "        sd_k = np.std(log_Wks_star, axis=0)\n",
    "        sim_sks = np.sqrt(1 + (1 / n_iterations)) * sd_k\n",
    "\n",
    "        gaps = np.mean(log_Wks_star - log_Wks, axis=0)\n",
    "\n",
    "        optimum = 1\n",
    "        max_gap = gaps[0]\n",
    "\n",
    "        # GAP - FORMULA (3)\n",
    "        for i in range(0, len(gaps) - 1):\n",
    "            if gaps[i] >= gaps[i + 1] - sim_sks[i + 1]:\n",
    "                if gaps[i] > max_gap:\n",
    "                    optimum = i\n",
    "                    max_gap = gaps[i]\n",
    "\n",
    "        self.params = {\n",
    "            'Wks': Wks,\n",
    "            'sim_Wks': sim_Wks,\n",
    "            'sim_sks': sim_sks,\n",
    "            'gaps': gaps\n",
    "        }\n",
    "\n",
    "        if self.return_params:\n",
    "            return optimum, self.params\n",
    "        else:\n",
    "            return optimum\n",
    "\n",
    "\n",
    "GapStatEucl = GapStatistics(return_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c13009",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "source": [
    "## Plotting the Gap Statistic <a class=\"anchor\" id=\"section_5_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfb138",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'KMedoids': KMedoids,\n",
    "    'AgglomerativeClustering': AgglomerativeClustering,\n",
    "    'SpectralClustering': SpectralClustering\n",
    "}\n",
    "\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "    optimum, params = GapStatEucl.fit_predict(algorithm,\n",
    "                                              K=15,\n",
    "                                              X=cluster_vars_gap)\n",
    "\n",
    "Wks = GapStatEucl.params['Wks']\n",
    "sim_Wks = GapStatEucl.params['sim_Wks']\n",
    "sim_sks = GapStatEucl.params['sim_sks']\n",
    "gaps = GapStatEucl.params['gaps']\n",
    "\n",
    "log_Wks = np.log(Wks)\n",
    "log_sim_Wks = np.log(np.mean(sim_Wks, axis=0))\n",
    "Wks = Wks - np.max(Wks)\n",
    "\n",
    "\n",
    "def clip_values(arr):\n",
    "    \"\"\"\n",
    "    Helper function to clip values in the array between 0 and 1.\n",
    "    \"\"\"\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = max(0, min(1, arr[i]))\n",
    "    return arr\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Bottom right\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(Wks, '-o', label=\"Wks from Data\")\n",
    "plt.plot(log_Wks, '-o', label=\"Logged Wks from Data\")\n",
    "plt.plot(log_sim_Wks, '-o', color=\"green\", label=f\"Logged Simulated Wks\")\n",
    "plt.title(\"Decrease of Within Cluster Distance\")\n",
    "plt.legend()\n",
    "\n",
    "# Bottom left\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(gaps, '-o', color='r')\n",
    "\n",
    "# Normalize yminx and ymaxsx to be between 0 and 1\n",
    "yminx = ((gaps - sim_sks) - np.min(gaps)) / (np.max(gaps) - np.min(gaps))\n",
    "ymaxsx = ((gaps + sim_sks) - np.min(gaps)) / (np.max(gaps) - np.min(gaps))\n",
    "\n",
    "# Clip values to ensure they are between 0 and 1\n",
    "clipped_yminx = clip_values(yminx)\n",
    "clipped_ymaxsx = clip_values(ymaxsx)\n",
    "\n",
    "# Plot vertical lines with clipped ymin and ymax\n",
    "for i in range(len(gaps)):\n",
    "    plt.axvline(x=i,\n",
    "                ymin=clipped_yminx[i],\n",
    "                ymax=clipped_ymaxsx[i],\n",
    "                color='black')\n",
    "\n",
    "plt.axvline(x=optimum, color='green')\n",
    "plt.title(\"Gap Statistics with optimum K at {}\".format(optimum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524895c",
   "metadata": {},
   "source": [
    "## The Gap Statistic with Gower's Distance <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c15d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapStatisticsGower:\n",
    "\n",
    "    def __init__(self, return_params: bool = False):\n",
    "\n",
    "        self.return_params = return_params\n",
    "\n",
    "    def _calculate_Wks(self, algorithm, K: int, X: pd.DataFrame) -> list:\n",
    "        dummy_columns = pd.get_dummies(X['InjuryHx.InjCause'])\n",
    "        X = pd.concat([X.drop('InjuryHx.InjCause', axis=1), dummy_columns],\n",
    "                      axis=1)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        Wks = []\n",
    "\n",
    "        for k in np.arange(2, K + 1):\n",
    "            if algorithm == KMedoids:\n",
    "                labels = algorithm(n_clusters=k, method='pam').fit_predict(X)\n",
    "            elif algorithm == AgglomerativeClustering:\n",
    "                labels = AgglomerativeClustering(\n",
    "                    n_clusters=k, linkage='average').fit_predict(X)\n",
    "            elif algorithm == SpectralClustering:\n",
    "                labels = SpectralClustering(\n",
    "                    n_clusters=k, affinity='nearest_neighbors').fit_predict(X)\n",
    "\n",
    "            X['labels'] = labels\n",
    "\n",
    "            Ds = []\n",
    "\n",
    "            for label in np.unique(X['labels']):\n",
    "                data = X[X['labels'] == label].drop(columns=['labels'])\n",
    "                n_k = len(data)\n",
    "                pooled = 1 / (2 * n_k)\n",
    "                d = np.sum(gower.gower_matrix(data))\n",
    "\n",
    "                Ds.append(d)\n",
    "\n",
    "            Wk = np.sum([D * pooled for D in Ds])\n",
    "            Wks.append(Wk)\n",
    "\n",
    "            X.drop(columns=['labels'], inplace=True)\n",
    "\n",
    "        return Wks\n",
    "\n",
    "    def _simulate_Wks(self, algorithm, X: pd.DataFrame, K: int,\n",
    "                      n_iterations: int) -> [list, list]:\n",
    "        cat_columns = [3, 4, 5, 6, 7]\n",
    "        cont_columns = [0, 1, 2, 8, 9, 10, 11]\n",
    "\n",
    "        cat = X.iloc[:, cat_columns]\n",
    "        cont = X.iloc[:, cont_columns]\n",
    "\n",
    "        sampled_X = X.copy()\n",
    "\n",
    "        for col in cat.columns:\n",
    "            sampled_X[col] = np.random.randint(low=cat[col].min(),\n",
    "                                               high=cat[col].max(),\n",
    "                                               size=len(X))\n",
    "\n",
    "        for col in cont.columns:\n",
    "            sampled_X[col] = np.random.uniform(low=cont[col].min(),\n",
    "                                               high=cont[col].max(),\n",
    "                                               size=len(X))\n",
    "\n",
    "        simulated_Wks = []\n",
    "\n",
    "        for i in range(n_iterations):\n",
    "\n",
    "            Wks_star = self._calculate_Wks(algorithm=algorithm,\n",
    "                                           K=K,\n",
    "                                           X=sampled_X)\n",
    "            simulated_Wks.append(Wks_star)\n",
    "\n",
    "        sim_Wks = np.array(simulated_Wks)\n",
    "        return sim_Wks\n",
    "\n",
    "    def fit_predict(self,\n",
    "                    algorithm,\n",
    "                    K: int,\n",
    "                    X: pd.DataFrame,\n",
    "                    n_iterations: int = 5):\n",
    "        Wks = self._calculate_Wks(algorithm=algorithm, K=K, X=X)\n",
    "        sim_Wks = self._simulate_Wks(algorithm=algorithm,\n",
    "                                     K=K,\n",
    "                                     X=X,\n",
    "                                     n_iterations=n_iterations)\n",
    "\n",
    "        log_Wks = np.log(Wks)\n",
    "        log_Wks_star = np.log(sim_Wks)\n",
    "\n",
    "        sd_k = np.std(log_Wks_star, axis=0)\n",
    "        sim_sks = np.sqrt(1 + (1 / n_iterations)) * sd_k\n",
    "\n",
    "        gaps = np.mean(log_Wks_star - log_Wks, axis=0)\n",
    "\n",
    "        optimum = 1\n",
    "        max_gap = gaps[0]\n",
    "\n",
    "        # GAP - FORMULA (3)\n",
    "        for i in range(0, len(gaps) - 1):\n",
    "            if gaps[i] >= gaps[i + 1] - sim_sks[i + 1]:\n",
    "                if gaps[i] > max_gap:\n",
    "                    optimum = i\n",
    "                    max_gap = gaps[i]\n",
    "\n",
    "        optimum = min(max(optimum, 1), K)\n",
    "\n",
    "        if self.return_params == True:\n",
    "            params = {\n",
    "                'Wks': Wks,\n",
    "                'sim_Wks': sim_Wks,\n",
    "                'sim_sks': sim_sks,\n",
    "                'gaps': gaps\n",
    "            }\n",
    "            return optimum, params\n",
    "        else:\n",
    "            return optimum\n",
    "\n",
    "\n",
    "GapStatGow = GapStatisticsGower(return_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac93ce1",
   "metadata": {},
   "source": [
    "## Stability Function: Rand & adjusted Rand Index <a class=\"anchor\" id=\"chapter7\"></a>\n",
    "\n",
    "This function calculates the stability of a clustering method given a number of bootstraps $B=200$ quantified via the Rand and adjusted Rand index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23e20094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_bootstrap(labels, n_bootstraps):\n",
    "\n",
    "    rands = []\n",
    "    arands = []\n",
    "\n",
    "    for i in range(0, n_bootstraps - 1):\n",
    "        for j in range(i + 1, n_bootstraps):\n",
    "\n",
    "            pairconf = pair_confusion_matrix(labels.iloc[:, i], labels.iloc[:,j])\n",
    "\n",
    "            a = pairconf[1, 1]  # pairs grouped together in both\n",
    "            b = pairconf[1, 0]\n",
    "            c = pairconf[0, 1]\n",
    "            d = pairconf[0, 0]  # pairs not grouped together in both\n",
    "\n",
    "            rand = (a + d) / (a + d + b + c)\n",
    "            arand = 2 * (a * d - b * c) / ((a + b) * (d + b) + (a + c) * (d + c))\n",
    "\n",
    "            rands.append(rand)\n",
    "            arands.append(arand)\n",
    "\n",
    "    scores = pd.DataFrame({'Rand': rands, 'Adjusted Rand': arands})\n",
    "\n",
    "    return print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67737a5",
   "metadata": {},
   "source": [
    "## Scenario 1 <a class=\"anchor\" id=\"chapter8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93dfaa9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: KM-Gow-Sil\n",
      "Number of unique labels: 12\n",
      "Smallest: 158\n",
      "Largest: 1167\n",
      "Average: 375.75\n",
      "Median: 248.0\n",
      "Silhouette score: 0.3253745399320117\n",
      "\n",
      "Algorithm: KM-Eucl-Sil\n",
      "Number of unique labels: 2\n",
      "Smallest: 1986\n",
      "Largest: 2523\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.5575120008521547\n",
      "\n",
      "Algorithm: AC-Gow-Sil\n",
      "Number of unique labels: 2\n",
      "Smallest: 2\n",
      "Largest: 4507\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.4498339110069868\n",
      "\n",
      "Algorithm: AC-Eucl-Sil\n",
      "Number of unique labels: 2\n",
      "Smallest: 1277\n",
      "Largest: 3232\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.49600126851626797\n",
      "\n",
      "Algorithm: SC-Gow-Sil\n",
      "Number of unique labels: 2\n",
      "Smallest: 1232\n",
      "Largest: 3277\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.39935160606537795\n",
      "\n",
      "Algorithm: SC-Eucl-Sil\n",
      "Number of unique labels: 2\n",
      "Smallest: 1901\n",
      "Largest: 2608\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.5572220758415105\n",
      "\n",
      "Algorithm: KM-Gow-Gap\n",
      "Number of unique labels: 15\n",
      "Smallest: 147\n",
      "Largest: 815\n",
      "Average: 300.6\n",
      "Median: 222.0\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n",
      "Algorithm: KM-Eucl-Gap\n",
      "Number of unique labels: 14\n",
      "Smallest: 124\n",
      "Largest: 453\n",
      "Average: 322.07142857142856\n",
      "Median: 327.5\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n",
      "Algorithm: AC-Gow-Gap\n",
      "Number of unique labels: 6\n",
      "Smallest: 1\n",
      "Largest: 4330\n",
      "Average: 751.5\n",
      "Median: 2.5\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n",
      "Algorithm: AC-Eucl-Gap\n",
      "Number of unique labels: 25\n",
      "Smallest: 1\n",
      "Largest: 774\n",
      "Average: 180.36\n",
      "Median: 90.0\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n",
      "Algorithm: SC-Gow-Gap\n",
      "Number of unique labels: 7\n",
      "Smallest: 141\n",
      "Largest: 1070\n",
      "Average: 644.1428571428571\n",
      "Median: 639.0\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n",
      "Algorithm: SC-Eucl-Gap\n",
      "Number of unique labels: 17\n",
      "Smallest: 29\n",
      "Largest: 474\n",
      "Average: 265.2352941176471\n",
      "Median: 316.0\n",
      "Silhouette score: Not applicable (Gap Method)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_algorithms():\n",
    "\n",
    "    kmedoids_sil_G12 = KMedoids(n_clusters=12,\n",
    "                                metric='precomputed',\n",
    "                                method='pam')\n",
    "\n",
    "    kmedoids_sil_E2 = KMedoids(n_clusters=2, method='pam')\n",
    "\n",
    "    agglomerative_sil_G2 = AgglomerativeClustering(n_clusters=2,\n",
    "                                                   affinity='precomputed',\n",
    "                                                   linkage='average')\n",
    "\n",
    "    agglomerative_sil_E2 = AgglomerativeClustering(n_clusters=2,\n",
    "                                                   linkage='average')\n",
    "\n",
    "    spectral_sil_G2 = SpectralClustering(n_clusters=2, affinity='precomputed')\n",
    "\n",
    "    spectral_sil_E2 = SpectralClustering(n_clusters=2,\n",
    "                                         affinity='nearest_neighbors')\n",
    "\n",
    "    kmedoids_gap_G15 = KMedoids(n_clusters=15,\n",
    "                                metric='precomputed',\n",
    "                                method='pam')\n",
    "\n",
    "    kmedoids_gap_E14 = KMedoids(n_clusters=14, method='pam')\n",
    "\n",
    "    agglomerative_gap_G6 = AgglomerativeClustering(n_clusters=6,\n",
    "                                                   affinity='precomputed',\n",
    "                                                   linkage='average')\n",
    "\n",
    "    agglomerative_gap_E25 = AgglomerativeClustering(n_clusters=25,\n",
    "                                                    linkage='average')\n",
    "\n",
    "    spectral_gap_G7 = SpectralClustering(n_clusters=7, affinity='precomputed')\n",
    "\n",
    "    spectral_gap_E17 = SpectralClustering(n_clusters=17,\n",
    "                                          affinity='nearest_neighbors')\n",
    "\n",
    "    return [('KM-Gow-Sil', kmedoids_sil_G12), ('KM-Eucl-Sil', kmedoids_sil_E2),\n",
    "            ('AC-Gow-Sil', agglomerative_sil_G2),\n",
    "            ('AC-Eucl-Sil', agglomerative_sil_E2),\n",
    "            ('SC-Gow-Sil', spectral_sil_G2), ('SC-Eucl-Sil', spectral_sil_E2),\n",
    "            ('KM-Gow-Gap', kmedoids_gap_G15),\n",
    "            ('KM-Eucl-Gap', kmedoids_gap_E14),\n",
    "            ('AC-Gow-Gap', agglomerative_gap_G6),\n",
    "            ('AC-Eucl-Gap', agglomerative_gap_E25),\n",
    "            ('SC-Gow-Gap', spectral_gap_G7), ('SC-Eucl-Gap', spectral_gap_E17)]\n",
    "\n",
    "\n",
    "clustering_algorithms = prepare_algorithms()\n",
    "\n",
    "\n",
    "def get_labels(X, X_distance, X_similarity):\n",
    "    labels = {}\n",
    "\n",
    "    for algorithm_name, algorithm in clustering_algorithms:\n",
    "        try:\n",
    "            if algorithm_name.startswith('SC') and algorithm_name.endswith(\n",
    "                ('Gow-Sil', 'Gow-Gap')):\n",
    "                algorithm.fit(X_similarity)\n",
    "            elif algorithm_name.startswith(\n",
    "                ('KM', 'AC')) and algorithm_name.endswith(\n",
    "                    ('Gow-Sil', 'Gow-Gap')):\n",
    "                algorithm.fit(X_distance)\n",
    "            else:\n",
    "                algorithm.fit(X)\n",
    "\n",
    "            if hasattr(algorithm, 'labels_'):\n",
    "                labels[algorithm_name] = algorithm.labels_.astype(int)\n",
    "            else:\n",
    "                raise AttributeError(\n",
    "                    f\"{algorithm_name} does not have a labels_ attribute.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {algorithm_name} could not be fitted. {e}\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "cluster_labels = get_labels(cluster_vars_encoded, gower_matrix,\n",
    "                            1 - gower_matrix)\n",
    "\n",
    "\n",
    "def print_label_counts(cluster_labels, X, X_distance):\n",
    "    if not cluster_labels:\n",
    "        print(\"Error: Input is empty.\")\n",
    "        return\n",
    "\n",
    "    for algorithm_name, labels in cluster_labels.items():\n",
    "        label_counts = Counter(labels)\n",
    "        cluster_sizes = list(label_counts.values())\n",
    "\n",
    "        print(f\"Algorithm: {algorithm_name}\")\n",
    "        print(f\"Number of unique labels: {len(label_counts)}\")\n",
    "        print(f\"Smallest: {min(cluster_sizes)}\")\n",
    "        print(f\"Largest: {max(cluster_sizes)}\")\n",
    "        print(f\"Average: {np.mean(cluster_sizes)}\")\n",
    "        print(f\"Median: {np.median(cluster_sizes)}\")\n",
    "\n",
    "        if len(label_counts) == 1:\n",
    "            print(\"Silhouette score: Not applicable (only one cluster)\\n\")\n",
    "            continue\n",
    "        if algorithm_name.endswith('Gap'):\n",
    "            print(\"Silhouette score: Not applicable (Gap Method)\\n\")\n",
    "            continue\n",
    "        if algorithm_name.endswith('Gow-Sil'):\n",
    "            silhouette = silhouette_score(X_distance,\n",
    "                                          labels,\n",
    "                                          metric='precomputed')\n",
    "            print(f\"Silhouette score: {silhouette}\\n\")\n",
    "        else:\n",
    "            silhouette = silhouette_score(X, labels, metric='euclidean')\n",
    "            print(f\"Silhouette score: {silhouette}\\n\")\n",
    "\n",
    "\n",
    "print_label_counts(cluster_labels, cluster_vars_encoded, gower_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de36b7f",
   "metadata": {},
   "source": [
    "## Scenario 1: Prognostic Value & Stability Bootstrap <a class=\"anchor\" id=\"chapter9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06f71ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         method  auc_apparent\n",
      "0    KM-Gow-Sil      0.539362\n",
      "1   KM-Eucl-Sil      0.554277\n",
      "2    AC-Gow-Sil      0.500599\n",
      "3   AC-Eucl-Sil      0.534569\n",
      "4    SC-Gow-Sil      0.642680\n",
      "5   SC-Eucl-Sil      0.553106\n",
      "6    KM-Gow-Gap      0.533356\n",
      "7   KM-Eucl-Gap      0.565788\n",
      "8    AC-Gow-Gap      0.526520\n",
      "9   AC-Eucl-Gap      0.526146\n",
      "10   SC-Gow-Gap      0.508309\n",
      "11  SC-Eucl-Gap      0.524000\n",
      "\n",
      "Algorithm: KMedoids \n",
      "Optimism Average: 0.06736299269552047 \n",
      "Std.dev. Bootstrap AUCs: 0.01816360189059788 \n",
      "\n",
      "Rand             0.819086\n",
      "Adjusted Rand    0.629046\n",
      "dtype: float64\n",
      "None\n",
      "\n",
      "Algorithm: AgglomerativeClustering \n",
      "Optimism Average: 0.020726690148392936 \n",
      "Std.dev. Bootstrap AUCs: 0.031092718206710765 \n",
      "\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "None\n",
      "\n",
      "Algorithm: SpectralClustering \n",
      "Optimism Average: 0.01820780055448712 \n",
      "Std.dev. Bootstrap AUCs: 0.028714227729293204 \n",
      "\n",
      "Rand             0.910228\n",
      "Adjusted Rand    0.824034\n",
      "dtype: float64\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine target variable (y_dich) with encoded cluster variables\n",
    "orig_data = pd.concat([y_dich, cluster_vars_encoded], axis=1)\n",
    "orig_data.columns = ['y_orig'] + list(cluster_vars_encoded.columns)\n",
    "\n",
    "# Combine target variable (y_dich) with gap-encoded cluster variables\n",
    "orig_data_gap = pd.concat([y_dich, cluster_vars_gap], axis=1)\n",
    "orig_data_gap.columns = ['y_orig'] + list(cluster_vars_gap.columns)\n",
    "\n",
    "# Set bootstrap iterations, range of clusters, fixed number of clusters (k)\n",
    "n_bootstraps = 10\n",
    "range_n_clusters = range(2, 20)\n",
    "k = 20\n",
    "\n",
    "# Lists to store AUC values and cluster labels\n",
    "aucs_bootstrap = []\n",
    "clusters = []\n",
    "\n",
    "# DataFrame to store AUC Apparent values for each algorithm\n",
    "auc_apparents = pd.DataFrame(columns=['method', 'auc_apparent'])\n",
    "\n",
    "# Dictionary of clustering algorithms and their corresponding classes\n",
    "algorithms = {\n",
    "    'KMedoids': KMedoids,\n",
    "    'AgglomerativeClustering': AgglomerativeClustering,\n",
    "    'SpectralClustering': SpectralClustering\n",
    "}\n",
    "\n",
    "# Iterate through clustering algorithms and calculate AUC Apparent\n",
    "for algorithm, labels in cluster_labels.items():\n",
    "    # Create DataFrame for logistic regression with cluster labels\n",
    "    df_orig = pd.DataFrame({\n",
    "        \"y_orig\": np.ravel(y_dich),\n",
    "        \"labels_orig\": np.ravel(labels)\n",
    "    })\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    model = sm.formula.glm(formula=\"y_orig ~ labels_orig\",\n",
    "                           family=sm.families.Binomial(),\n",
    "                           data=df_orig).fit()\n",
    "\n",
    "    # Calculate AUC Apparent\n",
    "    y_pred_apparent = model.predict(df_orig['labels_orig'])\n",
    "    auc_apparent = roc_auc_score(df_orig['y_orig'], y_pred_apparent)\n",
    "\n",
    "    # Append results to auc_apparents DataFrame\n",
    "    auc_apparents = auc_apparents.append(\n",
    "        {\n",
    "            'method': algorithm,\n",
    "            'auc_apparent': auc_apparent\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Display AUC Apparent values\n",
    "print(auc_apparents)\n",
    "print()\n",
    "\n",
    "# Iterate through clustering algorithms and perform bootstrap iterations\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "\n",
    "    # Lists to store optimism values and cluster labels\n",
    "    optimisms = []\n",
    "    labels_origs = pd.DataFrame()\n",
    "\n",
    "    # Perform bootstrap iterations\n",
    "    for i in range(n_bootstraps):\n",
    "        # Resample data for bootstrap\n",
    "        sample = resample(orig_data, replace=True, n_samples=4509)\n",
    "        sample_gap = resample(orig_data_gap, replace=True, n_samples=4509)\n",
    "\n",
    "        # Extract target variable from resampled data\n",
    "        y_boot = sample['y_orig']\n",
    "\n",
    "        # Calculate the best number of clusters\n",
    "        n_eucl_sil = best_silhouette_euclidean(algorithm, sample.iloc[:, 1:],\n",
    "                                               range_n_clusters)[0]\n",
    "\n",
    "        # n_gow_sil = best_silhouette_gower(algorithm, gower.gower_matrix(sample.iloc[:, 1:]),range_n_clusters)[0]\n",
    "\n",
    "        # n_eucl_gap = GapStatEucl.fit_predict(algorithm, k, sample_gap.iloc[:,1:])\n",
    "\n",
    "        # n_gow_gap = GapStatGow.fit_predict(algorithm, k, sample_gap.iloc[:,1:])\n",
    "\n",
    "        #\n",
    "\n",
    "        # (2) AUC Bootstrap\n",
    "\n",
    "        try:\n",
    "            if algorithm == KMedoids:\n",
    "                clusterer = KMedoids(n_clusters=n_eucl_sil).fit(\n",
    "                    sample.iloc[:, 1:])\n",
    "                labels_orig = pd.DataFrame(\n",
    "                    clusterer.predict(orig_data.iloc[:, 1:]))\n",
    "\n",
    "            elif algorithm == AgglomerativeClustering:\n",
    "                clusterer = AgglomerativeClustering(n_clusters=n_eucl_sil,\n",
    "                                                    linkage='average').fit(\n",
    "                                                        sample.iloc[:, 1:])\n",
    "                labels_orig = pd.DataFrame(\n",
    "                    clusterer.fit_predict(orig_data.iloc[:, 1:]))\n",
    "\n",
    "            elif algorithm == SpectralClustering:\n",
    "                clusterer = SpectralClustering(\n",
    "                    n_clusters=n_eucl_sil,\n",
    "                    affinity='nearest_neighbors').fit(sample.iloc[:, 1:])\n",
    "                labels_orig = pd.DataFrame(\n",
    "                    clusterer.fit_predict(orig_data.iloc[:, 1:]))\n",
    "\n",
    "            # Get labels and fit logistic regression model\n",
    "            labels_boot = pd.DataFrame(clusterer.labels_)\n",
    "            df_boot = pd.DataFrame({\n",
    "                \"y_boot\": np.ravel(y_boot),\n",
    "                \"labels_boot\": np.ravel(labels_boot)\n",
    "            })\n",
    "\n",
    "            model = sm.formula.glm(formula=\"y_boot ~ labels_boot\",\n",
    "                                   family=sm.families.Binomial(),\n",
    "                                   data=df_boot).fit()\n",
    "\n",
    "            # Calculate AUC Bootstrap\n",
    "            y_pred_boot = model.predict(labels_boot)\n",
    "            auc_bootstrap = roc_auc_score(y_boot, y_pred_boot)\n",
    "            aucs_bootstrap.append(auc_bootstrap)\n",
    "\n",
    "            # Calculate AUC Original\n",
    "            y_pred_orig = model.predict(pd.DataFrame(labels_orig))\n",
    "            auc_original = roc_auc_score(df_orig['y_orig'], y_pred_orig)\n",
    "\n",
    "            # Calculate optimism and append results\n",
    "            optimism = auc_bootstrap - auc_original\n",
    "            optimisms.append(optimism)\n",
    "            labels_origs = pd.concat([labels_origs, labels_orig], axis=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", str(e))\n",
    "            continue\n",
    "\n",
    "    # Calculate average optimism\n",
    "    optimism_avg = np.mean(optimisms)\n",
    "\n",
    "    std_aucs_bootstrap = np.std(aucs_bootstrap)\n",
    "\n",
    "    print(f\"Algorithm: {algorithm_name} \\n\"\n",
    "          f\"Optimism Average: {optimism_avg} \\n\"\n",
    "          f\"Std.dev. Bootstrap AUCs: {std_aucs_bootstrap} \\n\")\n",
    "\n",
    "    #         auc_o = auc_apparent - optimism_avg\n",
    "\n",
    "    #         ci = [\n",
    "    #             auc_o - 1.96 * np.std(aucs_bootstrap),\n",
    "    #             auc_o + 1.96 * np.std(aucs_bootstrap)\n",
    "    #         ]\n",
    "\n",
    "    # Stability\n",
    "\n",
    "    stability = stability_bootstrap(labels_origs, n_bootstraps)\n",
    "\n",
    "    print(stability)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e75f96",
   "metadata": {},
   "source": [
    "## Scenario 1: OLS of adjusted Rand Stability Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be54b21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.159\n",
      "Model:                            OLS   Adj. R-squared:                 -0.322\n",
      "Method:                 Least Squares   F-statistic:                    0.3301\n",
      "Date:                Fri, 26 Jan 2024   Prob (F-statistic):              0.850\n",
      "Time:                        16:43:31   Log-Likelihood:                 1.8867\n",
      "No. Observations:                  12   AIC:                             6.227\n",
      "Df Residuals:                       7   BIC:                             8.651\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.7250      0.175      4.149      0.004       0.312       1.138\n",
      "algorithm_KM    -0.1650      0.191     -0.862      0.417      -0.618       0.288\n",
      "algorithm_SC    -0.0150      0.191     -0.078      0.940      -0.468       0.438\n",
      "distance_Gow    -0.0933      0.156     -0.597      0.569      -0.463       0.276\n",
      "method_Sil      -0.0367      0.156     -0.235      0.821      -0.406       0.333\n",
      "==============================================================================\n",
      "Omnibus:                        1.957   Durbin-Watson:                   2.656\n",
      "Prob(Omnibus):                  0.376   Jarque-Bera (JB):                1.427\n",
      "Skew:                           0.728   Prob(JB):                        0.490\n",
      "Kurtosis:                       2.142   Cond. No.                         4.67\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'algorithm':\n",
    "    ['AC', 'KM', 'SC', 'AC', 'KM', 'SC', 'AC', 'KM', 'SC', 'AC', 'KM', 'SC'],\n",
    "    'distance': [\n",
    "        'Gow', 'Gow', 'Gow', 'Eucl', 'Eucl', 'Eucl', 'Gow', 'Gow', 'Gow',\n",
    "        'Eucl', 'Eucl', 'Eucl'\n",
    "    ],\n",
    "    'method': [\n",
    "        'Sil', 'Sil', 'Sil', 'Sil', 'Sil', 'Sil', 'Gap', 'Gap', 'Gap', 'Gap',\n",
    "        'Gap', 'Gap'\n",
    "    ],\n",
    "    'value':\n",
    "    [0.47, 0.20, 0.98, 0.60, 0.67, 0.57, 0.96, 0.34, 0.37, 0.61, 0.77, 0.66]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df,\n",
    "                            columns=['algorithm', 'distance', 'method'],\n",
    "                            prefix=['algorithm', 'distance', 'method'],\n",
    "                            drop_first=True)\n",
    "\n",
    "X = df_encoded[['algorithm_KM', 'algorithm_SC', 'distance_Gow', 'method_Sil']]\n",
    "y = df['value']\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS (Ordinary Least Squares) model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Summary of the logistic regression model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22d96e",
   "metadata": {},
   "source": [
    "## Scenario 1: SHAP Analysis <a class=\"anchor\" id=\"chapter10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50ed5712",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AC-Gow-Sil\n",
      "                             feature  mean_shap_value\n",
      "1                               dim4         0.000655\n",
      "2                               dim3         0.000388\n",
      "3                               dim2         0.000352\n",
      "4                               dim1         0.000324\n",
      "5   InjuryHx.GCSScoreBaselineDerived         0.000250\n",
      "6                   Violence/suicide         0.000201\n",
      "7   InjuryHx.MajorExtracranialInjury         0.000129\n",
      "8                        Subject.Age         0.000128\n",
      "9   InjuryHx.EDComplEventHypotension         0.000112\n",
      "10  InjuryHx.GCSMotorBaselineDerived         0.000101\n",
      "11                               RTA         0.000049\n",
      "12    InjuryHx.PupilsBaselineDerived         0.000030\n",
      "13                              Fall         0.000015\n",
      "14      InjuryHx.EDComplEventHypoxia         0.000004\n",
      "15                             Other         0.000001\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KM-Gow-Sil\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.039772\n",
      "1                               dim3         0.044509\n",
      "2                               dim2         0.054057\n",
      "3                               dim1         0.129384\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.630322\n",
      "5                   Violence/suicide         0.112113\n",
      "6   InjuryHx.MajorExtracranialInjury         0.101061\n",
      "7                        Subject.Age         0.049343\n",
      "8   InjuryHx.EDComplEventHypotension         0.039310\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.452726\n",
      "10                               RTA         0.464355\n",
      "11    InjuryHx.PupilsBaselineDerived         0.087801\n",
      "12                              Fall         0.550210\n",
      "13      InjuryHx.EDComplEventHypoxia         0.050153\n",
      "14                             Other         0.120195\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: SC-Gow-Sil\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.017319\n",
      "1                               dim3         0.019783\n",
      "2                               dim2         0.023400\n",
      "3                               dim1         0.084028\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.233698\n",
      "5                   Violence/suicide         0.002316\n",
      "6   InjuryHx.MajorExtracranialInjury         0.080202\n",
      "7                        Subject.Age         0.011338\n",
      "8   InjuryHx.EDComplEventHypotension         0.021723\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.329446\n",
      "10                               RTA         0.039245\n",
      "11    InjuryHx.PupilsBaselineDerived         0.051003\n",
      "12                              Fall         0.060457\n",
      "13      InjuryHx.EDComplEventHypoxia         0.029083\n",
      "14                             Other         0.002641\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: AC-Eucl-Sil\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.007434\n",
      "1                               dim3         0.011604\n",
      "2                               dim2         0.011145\n",
      "3                               dim1         0.016341\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.034813\n",
      "5                   Violence/suicide         0.005284\n",
      "6   InjuryHx.MajorExtracranialInjury         0.002633\n",
      "7                        Subject.Age         0.720513\n",
      "8   InjuryHx.EDComplEventHypotension         0.002132\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.019807\n",
      "10                               RTA         0.015423\n",
      "11    InjuryHx.PupilsBaselineDerived         0.002517\n",
      "12                              Fall         0.047503\n",
      "13      InjuryHx.EDComplEventHypoxia         0.001700\n",
      "14                             Other         0.001613\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KM-Eucl-Sil\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.012947\n",
      "1                               dim3         0.015380\n",
      "2                               dim2         0.012164\n",
      "3                               dim1         0.027249\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.013197\n",
      "5                   Violence/suicide         0.019220\n",
      "6   InjuryHx.MajorExtracranialInjury         0.003072\n",
      "7                        Subject.Age         0.883124\n",
      "8   InjuryHx.EDComplEventHypotension         0.002398\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.008484\n",
      "10                               RTA         0.025120\n",
      "11    InjuryHx.PupilsBaselineDerived         0.002322\n",
      "12                              Fall         0.053613\n",
      "13      InjuryHx.EDComplEventHypoxia         0.002227\n",
      "14                             Other         0.002385\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: SC-Eucl-Sil\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.010849\n",
      "1                               dim3         0.016789\n",
      "2                               dim2         0.012276\n",
      "3                               dim1         0.025411\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.018333\n",
      "5                   Violence/suicide         0.014996\n",
      "6   InjuryHx.MajorExtracranialInjury         0.004091\n",
      "7                        Subject.Age         0.872102\n",
      "8   InjuryHx.EDComplEventHypotension         0.002887\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.014359\n",
      "10                               RTA         0.022773\n",
      "11    InjuryHx.PupilsBaselineDerived         0.002499\n",
      "12                              Fall         0.051140\n",
      "13      InjuryHx.EDComplEventHypoxia         0.002353\n",
      "14                             Other         0.001582\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: AC-Gow-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.003759\n",
      "1                               dim3         0.005589\n",
      "2                               dim2         0.007137\n",
      "3                               dim1         0.004489\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.021477\n",
      "5                   Violence/suicide         0.001170\n",
      "6   InjuryHx.MajorExtracranialInjury         0.020263\n",
      "7                        Subject.Age         0.003728\n",
      "8   InjuryHx.EDComplEventHypotension         0.031453\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.027499\n",
      "10                               RTA         0.002999\n",
      "11    InjuryHx.PupilsBaselineDerived         0.012039\n",
      "12                              Fall         0.001610\n",
      "13      InjuryHx.EDComplEventHypoxia         0.087262\n",
      "14                             Other         0.000482\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KM-Gow-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.044882\n",
      "1                               dim3         0.050398\n",
      "2                               dim2         0.057940\n",
      "3                               dim1         0.144458\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.615174\n",
      "5                   Violence/suicide         0.103208\n",
      "6   InjuryHx.MajorExtracranialInjury         0.117117\n",
      "7                        Subject.Age         0.286877\n",
      "8   InjuryHx.EDComplEventHypotension         0.038604\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.456125\n",
      "10                               RTA         0.505117\n",
      "11    InjuryHx.PupilsBaselineDerived         0.077654\n",
      "12                              Fall         0.526213\n",
      "13      InjuryHx.EDComplEventHypoxia         0.047156\n",
      "14                             Other         0.118657\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: SC-Gow-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.034486\n",
      "1                               dim3         0.030512\n",
      "2                               dim2         0.036730\n",
      "3                               dim1         0.102457\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.296559\n",
      "5                   Violence/suicide         0.046954\n",
      "6   InjuryHx.MajorExtracranialInjury         0.386451\n",
      "7                        Subject.Age         0.268373\n",
      "8   InjuryHx.EDComplEventHypotension         0.050238\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.354445\n",
      "10                               RTA         0.450173\n",
      "11    InjuryHx.PupilsBaselineDerived         0.071497\n",
      "12                              Fall         0.253942\n",
      "13      InjuryHx.EDComplEventHypoxia         0.053410\n",
      "14                             Other         0.053390\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AC-Eucl-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.064661\n",
      "1                               dim3         0.071560\n",
      "2                               dim2         0.053835\n",
      "3                               dim1         0.104999\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.421285\n",
      "5                   Violence/suicide         0.020932\n",
      "6   InjuryHx.MajorExtracranialInjury         0.021658\n",
      "7                        Subject.Age         1.213065\n",
      "8   InjuryHx.EDComplEventHypotension         0.012041\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.242361\n",
      "10                               RTA         0.043503\n",
      "11    InjuryHx.PupilsBaselineDerived         0.032580\n",
      "12                              Fall         0.094412\n",
      "13      InjuryHx.EDComplEventHypoxia         0.016640\n",
      "14                             Other         0.008866\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KM-Eucl-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.065593\n",
      "1                               dim3         0.074546\n",
      "2                               dim2         0.047511\n",
      "3                               dim1         0.107491\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.412801\n",
      "5                   Violence/suicide         0.028011\n",
      "6   InjuryHx.MajorExtracranialInjury         0.027744\n",
      "7                        Subject.Age         1.234793\n",
      "8   InjuryHx.EDComplEventHypotension         0.012584\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.207961\n",
      "10                               RTA         0.045474\n",
      "11    InjuryHx.PupilsBaselineDerived         0.036332\n",
      "12                              Fall         0.097121\n",
      "13      InjuryHx.EDComplEventHypoxia         0.018026\n",
      "14                             Other         0.010428\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: SC-Eucl-Gap\n",
      "                             feature  mean_shap_value\n",
      "0                               dim4         0.063862\n",
      "1                               dim3         0.080116\n",
      "2                               dim2         0.070069\n",
      "3                               dim1         0.116264\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.502106\n",
      "5                   Violence/suicide         0.024134\n",
      "6   InjuryHx.MajorExtracranialInjury         0.030867\n",
      "7                        Subject.Age         1.241351\n",
      "8   InjuryHx.EDComplEventHypotension         0.012988\n",
      "9   InjuryHx.GCSMotorBaselineDerived         0.206902\n",
      "10                               RTA         0.045789\n",
      "11    InjuryHx.PupilsBaselineDerived         0.028823\n",
      "12                              Fall         0.117236\n",
      "13      InjuryHx.EDComplEventHypoxia         0.018637\n",
      "14                             Other         0.011069\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1 = cluster_labels['AC-Gow-Sil']\n",
    "y2 = cluster_labels['KM-Gow-Sil']\n",
    "y3 = cluster_labels['SC-Gow-Sil']\n",
    "y4 = cluster_labels['AC-Eucl-Sil']\n",
    "y5 = cluster_labels['KM-Eucl-Sil']\n",
    "y6 = cluster_labels['SC-Eucl-Sil']\n",
    "y7 = cluster_labels['AC-Gow-Gap']\n",
    "y8 = cluster_labels['KM-Gow-Gap']\n",
    "y9 = cluster_labels['SC-Gow-Gap']\n",
    "y10 = cluster_labels['AC-Eucl-Gap']\n",
    "y11 = cluster_labels['KM-Eucl-Gap']\n",
    "y12 = cluster_labels['SC-Eucl-Gap']\n",
    "\n",
    "cluster_labels_list = [(y1, 'AC-Gow-Sil'), (y2, 'KM-Gow-Sil'),\n",
    "                       (y3, 'SC-Gow-Sil'), (y4, 'AC-Eucl-Sil'),\n",
    "                       (y5, 'KM-Eucl-Sil'), (y6, 'SC-Eucl-Sil'),\n",
    "                       (y7, 'AC-Gow-Gap'), (y8, 'KM-Gow-Gap'),\n",
    "                       (y9, 'SC-Gow-Gap'), (y10, 'AC-Eucl-Gap'),\n",
    "                       (y11, 'KM-Eucl-Gap'), (y12, 'SC-Eucl-Gap')]\n",
    "\n",
    "\n",
    "def shap_feature_ranking(data, shap_values, columns=None):\n",
    "    if columns is None:\n",
    "        columns = data.columns.tolist()\n",
    "\n",
    "    # Get column indices for the specified columns\n",
    "    c_idxs = [data.columns.get_loc(column) for column in columns]\n",
    "\n",
    "    # Calculate mean shap values\n",
    "    if isinstance(shap_values, list):\n",
    "        means = [\n",
    "            np.abs(shap_values[class_][:, c_idxs]).mean(axis=0)\n",
    "            for class_ in range(len(shap_values))\n",
    "        ]\n",
    "        shap_means = np.sum(np.column_stack(means), axis=1)\n",
    "    else:\n",
    "        assert len(shap_values.shape) == 2, 'Expected two-dimensional shap values array.'\n",
    "        shap_means = np.abs(shap_values[:, c_idxs]).mean(axis=0)\n",
    "\n",
    "    df_ranking = pd.DataFrame({\n",
    "        'feature': columns,\n",
    "        'mean_shap_value': shap_means\n",
    "    })\n",
    "\n",
    "    df_ranking = df_ranking.sort_values(by='mean_shap_value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df_ranking.index += 1\n",
    "\n",
    "    return df_ranking\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Perform SHAP analysis for each cluster label\n",
    "for i, (cluster_label, label_name) in enumerate(cluster_labels_list, start=1):\n",
    "    # Create and fit the RandomForestClassifier\n",
    "    clf.fit(cluster_vars_encoded, cluster_label)\n",
    "\n",
    "    # Create a TreeExplainer\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "    # Calculate SHAP values for all samples\n",
    "    shap_values = explainer.shap_values(cluster_vars_encoded)\n",
    "\n",
    "    # Get the feature ranking\n",
    "    feature_ranking = shap_feature_ranking(cluster_vars_encoded, shap_values)\n",
    "\n",
    "    # Align feature order based on the first model's order\n",
    "    if i == 1:\n",
    "        feature_order = feature_ranking['feature'].tolist()\n",
    "    else:\n",
    "        feature_ranking = feature_ranking.set_index('feature').reindex(feature_order).reset_index()\n",
    "\n",
    "    # Print the model name\n",
    "    print(f'Model: {label_name}')\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(feature_ranking)\n",
    "    print('\\n' + '-' * 50 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d6ba8",
   "metadata": {},
   "source": [
    "## GridSearch Gaussian Mixture <a class=\"anchor\" id=\"chapter11\"></a>\n",
    " \n",
    "Sklearn's default value for the number of components in the Gaussian Mixture clustering algorithm is 1. Therefore, we performed a grid search to find an alternative number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdd445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gmm_bic_score(estimator, X):\n",
    "    return -estimator.bic(X)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_components\": range(1, 35),\n",
    "    \"covariance_type\": [\"spherical\", \"tied\", \"diag\", \"full\"],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV 20 times\n",
    "for i in range(20):\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=GaussianMixture(),\n",
    "                               param_grid=param_grid,\n",
    "                               scoring=gmm_bic_score)\n",
    "\n",
    "    # Fit the model using scaled encoded cluster variables\n",
    "    grid_search.fit(cluster_vars_encoded_scaled)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame(grid_search.cv_results_,\n",
    "                      columns=[\n",
    "                          \"param_n_components\", \"param_covariance_type\",\n",
    "                          \"mean_test_score\"\n",
    "                      ])\n",
    "\n",
    "    # Calculate BIC score and update DataFrame\n",
    "    df[\"BIC score\"] = -df[\"mean_test_score\"]\n",
    "    df.drop('mean_test_score', axis=1, inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.rename(columns={\n",
    "        \"param_n_components\": \"Number of components\",\n",
    "        \"param_covariance_type\": \"Type of covariance\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Sort DataFrame by BIC score\n",
    "    df.sort_values(by=\"BIC score\", inplace=True)\n",
    "\n",
    "    # Display the top rows of the DataFrame\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c653f2b",
   "metadata": {},
   "source": [
    "## Scenario 2 <a class=\"anchor\" id=\"chapter12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94677eeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: KMeans\n",
      "Number of unique labels: 8\n",
      "Largest: 1268\n",
      "Smallest: 38\n",
      "Average: 563.625\n",
      "Median: 414.0\n",
      "Silhouette score: 0.2264868767099228\n",
      "\n",
      "Algorithm: KMedoids\n",
      "Number of unique labels: 8\n",
      "Largest: 941\n",
      "Smallest: 321\n",
      "Average: 563.625\n",
      "Median: 480.0\n",
      "Silhouette score: 0.12960692600107326\n",
      "\n",
      "Algorithm: GaussianMixture\n",
      "Number of unique labels: 45\n",
      "Largest: 680\n",
      "Smallest: 1\n",
      "Average: 100.2\n",
      "Median: 30.0\n",
      "Silhouette score: -0.017768495917285666\n",
      "\n",
      "Algorithm: AgglomerativeClustering\n",
      "Number of unique labels: 2\n",
      "Largest: 4471\n",
      "Smallest: 38\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.6394671984671255\n",
      "\n",
      "Algorithm: Ward\n",
      "Number of unique labels: 2\n",
      "Largest: 3354\n",
      "Smallest: 1155\n",
      "Average: 2254.5\n",
      "Median: 2254.5\n",
      "Silhouette score: 0.35348708254701217\n",
      "\n",
      "Algorithm: SpectralClustering\n",
      "Number of unique labels: 8\n",
      "Largest: 4298\n",
      "Smallest: 12\n",
      "Average: 563.625\n",
      "Median: 18.0\n",
      "Silhouette score: -0.3474853552040643\n",
      "\n",
      "Algorithm: BIRCH\n",
      "Number of unique labels: 3\n",
      "Largest: 3849\n",
      "Smallest: 38\n",
      "Average: 1503.0\n",
      "Median: 622.0\n",
      "Silhouette score: 0.31462137186023365\n",
      "\n",
      "Algorithm: Mean Shift\n",
      "Number of unique labels: 10\n",
      "Largest: 4363\n",
      "Smallest: 1\n",
      "Average: 450.9\n",
      "Median: 1.0\n",
      "Silhouette score: 0.3927190223878103\n",
      "\n",
      "Algorithm: AffinityPropagation\n",
      "Number of unique labels: 450\n",
      "Largest: 210\n",
      "Smallest: 1\n",
      "Average: 10.02\n",
      "Median: 2.0\n",
      "Silhouette score: 0.1492181475905564\n",
      "\n",
      "Algorithm: DBSCAN\n",
      "Number of unique labels: 48\n",
      "Largest: 2386\n",
      "Smallest: 5\n",
      "Average: 93.9375\n",
      "Median: 11.0\n",
      "Silhouette score: -0.21623392628898147\n",
      "\n",
      "Algorithm: OPTICS\n",
      "Number of unique labels: 224\n",
      "Largest: 2611\n",
      "Smallest: 5\n",
      "Average: 20.129464285714285\n",
      "Median: 8.0\n",
      "Silhouette score: -0.0502630174388143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_algorithms():\n",
    "\n",
    "    kmeans = KMeans()\n",
    "    kmedoids = KMedoids()\n",
    "    gmm = GaussianMixture(n_components=45, covariance_type='diag')\n",
    "    average_linkage = AgglomerativeClustering(linkage='average')\n",
    "    ward = AgglomerativeClustering(linkage='ward')\n",
    "    spectral = SpectralClustering(affinity='nearest_neighbors')\n",
    "    birch = Birch()\n",
    "    mean_shift = MeanShift()\n",
    "    affinity_propagation = AffinityPropagation()\n",
    "    dbscan = DBSCAN()\n",
    "    optics = OPTICS()\n",
    "\n",
    "    return [('KMeans', kmeans), ('KMedoids', kmedoids),\n",
    "            ('GaussianMixture', gmm),\n",
    "            ('AgglomerativeClustering', average_linkage), ('Ward', ward),\n",
    "            ('SpectralClustering', spectral), ('BIRCH', birch),\n",
    "            ('Mean Shift', mean_shift),\n",
    "            ('AffinityPropagation', affinity_propagation), ('DBSCAN', dbscan),\n",
    "            ('OPTICS', optics)]\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 4,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "    \"random_state\": 42,\n",
    "    \"metric\": 'precomputed'\n",
    "}\n",
    "\n",
    "clustering_algorithms = prepare_algorithms()\n",
    "\n",
    "\n",
    "def get_labels(data):\n",
    "    labels = {}\n",
    "\n",
    "    for algorithm_name, algorithm in clustering_algorithms:\n",
    "        try:\n",
    "            algorithm.fit(data)\n",
    "            if hasattr(algorithm, 'labels_'):\n",
    "                labels[algorithm_name] = algorithm.labels_.astype(int)\n",
    "            elif hasattr(algorithm, 'predict'):\n",
    "                labels[algorithm_name] = algorithm.predict(data)\n",
    "            else:\n",
    "                raise AttributeError(\n",
    "                    f\"{algorithm_name} does not have a labels_ attribute or a predict method.\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {algorithm_name} could not be fitted. {e}\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "cluster_labels = get_labels(cluster_vars_encoded_scaled)\n",
    "\n",
    "\n",
    "def print_label_counts(cluster_labels, X):\n",
    "    if not cluster_labels:\n",
    "        print(\"Error: Input is empty.\")\n",
    "        return\n",
    "\n",
    "    for algorithm_name, labels in cluster_labels.items():\n",
    "        label_counts = Counter(labels)\n",
    "        cluster_sizes = list(label_counts.values())\n",
    "\n",
    "        print(f\"Algorithm: {algorithm_name}\")\n",
    "        print(f\"Number of unique labels: {len(label_counts)}\")\n",
    "        print(f\"Largest: {max(cluster_sizes)}\")\n",
    "        print(f\"Smallest: {min(cluster_sizes)}\")\n",
    "        print(f\"Average: {np.mean(cluster_sizes)}\")\n",
    "        print(f\"Median: {np.median(cluster_sizes)}\")\n",
    "\n",
    "        if len(label_counts) == 1:\n",
    "            print(\"Silhouette score: Not applicable (only one cluster)\\n\")\n",
    "        else:\n",
    "            silhouette = silhouette_score(X, labels, metric='euclidean')\n",
    "            print(f\"Silhouette score: {silhouette}\\n\")\n",
    "\n",
    "\n",
    "print_label_counts(cluster_labels, cluster_vars_encoded_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b75699",
   "metadata": {},
   "source": [
    "## Print the Top Ten Largest Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa9118e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Top 10 Label Counts:\n",
      "Label: 5, Count: 1268\n",
      "Label: 3, Count: 1262\n",
      "Label: 0, Count: 660\n",
      "Label: 1, Count: 431\n",
      "Label: 6, Count: 397\n",
      "Label: 4, Count: 353\n",
      "Label: 2, Count: 100\n",
      "Label: 7, Count: 38\n",
      "\n",
      "KMedoids Top 10 Label Counts:\n",
      "Label: 7, Count: 941\n",
      "Label: 3, Count: 759\n",
      "Label: 0, Count: 748\n",
      "Label: 4, Count: 510\n",
      "Label: 2, Count: 450\n",
      "Label: 5, Count: 416\n",
      "Label: 6, Count: 364\n",
      "Label: 1, Count: 321\n",
      "\n",
      "GaussianMixture Top 10 Label Counts:\n",
      "Label: 21, Count: 680\n",
      "Label: 6, Count: 520\n",
      "Label: 17, Count: 443\n",
      "Label: 41, Count: 427\n",
      "Label: 8, Count: 324\n",
      "Label: 14, Count: 256\n",
      "Label: 0, Count: 220\n",
      "Label: 26, Count: 198\n",
      "Label: 43, Count: 183\n",
      "Label: 27, Count: 169\n",
      "\n",
      "AgglomerativeClustering Top 10 Label Counts:\n",
      "Label: 0, Count: 4471\n",
      "Label: 1, Count: 38\n",
      "\n",
      "Ward Top 10 Label Counts:\n",
      "Label: 1, Count: 3354\n",
      "Label: 0, Count: 1155\n",
      "\n",
      "SpectralClustering Top 10 Label Counts:\n",
      "Label: 0, Count: 4298\n",
      "Label: 2, Count: 103\n",
      "Label: 4, Count: 31\n",
      "Label: 3, Count: 18\n",
      "Label: 6, Count: 18\n",
      "Label: 7, Count: 17\n",
      "Label: 5, Count: 12\n",
      "Label: 1, Count: 12\n",
      "\n",
      "BIRCH Top 10 Label Counts:\n",
      "Label: 0, Count: 3849\n",
      "Label: 2, Count: 622\n",
      "Label: 1, Count: 38\n",
      "\n",
      "Mean Shift Top 10 Label Counts:\n",
      "Label: 0, Count: 4363\n",
      "Label: 1, Count: 108\n",
      "Label: 2, Count: 29\n",
      "Label: 3, Count: 3\n",
      "Label: 5, Count: 1\n",
      "Label: 9, Count: 1\n",
      "Label: 7, Count: 1\n",
      "Label: 4, Count: 1\n",
      "Label: 6, Count: 1\n",
      "Label: 8, Count: 1\n",
      "\n",
      "AffinityPropagation Top 10 Label Counts:\n",
      "Label: 179, Count: 210\n",
      "Label: 120, Count: 204\n",
      "Label: 310, Count: 163\n",
      "Label: 41, Count: 137\n",
      "Label: 187, Count: 77\n",
      "Label: 92, Count: 64\n",
      "Label: 311, Count: 64\n",
      "Label: 238, Count: 61\n",
      "Label: 183, Count: 60\n",
      "Label: 262, Count: 59\n",
      "\n",
      "DBSCAN Top 10 Label Counts:\n",
      "Label: -1, Count: 2386\n",
      "Label: 1, Count: 662\n",
      "Label: 0, Count: 484\n",
      "Label: 6, Count: 124\n",
      "Label: 10, Count: 105\n",
      "Label: 4, Count: 90\n",
      "Label: 3, Count: 75\n",
      "Label: 11, Count: 46\n",
      "Label: 18, Count: 41\n",
      "Label: 2, Count: 38\n",
      "\n",
      "OPTICS Top 10 Label Counts:\n",
      "Label: -1, Count: 2611\n",
      "Label: 196, Count: 23\n",
      "Label: 204, Count: 21\n",
      "Label: 48, Count: 20\n",
      "Label: 54, Count: 19\n",
      "Label: 49, Count: 19\n",
      "Label: 119, Count: 18\n",
      "Label: 163, Count: 18\n",
      "Label: 82, Count: 17\n",
      "Label: 65, Count: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store label counts for each method\n",
    "method_label_counts = {}\n",
    "\n",
    "# Iterate through each method in the dictionary\n",
    "for method, labels in cluster_labels.items():\n",
    "    # Count the occurrences of each label for the current method\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    # Store the label counts in the dictionary\n",
    "    method_label_counts[method] = label_counts\n",
    "\n",
    "# Print the top 10 label counts for each method\n",
    "for method, label_counts in method_label_counts.items():\n",
    "    print(f\"{method} Top 10 Label Counts:\")\n",
    "    for label, count in label_counts.most_common(10):\n",
    "        print(f\"Label: {label}, Count: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb5fbd",
   "metadata": {},
   "source": [
    "## Scenario 2: SHAP Analysis <a class=\"anchor\" id=\"chapter13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2a872f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AffinityPropagation\n",
      "                             feature  mean_shap_value\n",
      "1                        Subject.Age         1.006467\n",
      "2                               dim1         0.557946\n",
      "3                               Fall         0.523707\n",
      "4                                RTA         0.495838\n",
      "5   InjuryHx.GCSScoreBaselineDerived         0.428874\n",
      "6                               dim2         0.428456\n",
      "7                               dim3         0.424597\n",
      "8   InjuryHx.GCSMotorBaselineDerived         0.362633\n",
      "9                               dim4         0.267288\n",
      "10  InjuryHx.MajorExtracranialInjury         0.150759\n",
      "11                             Other         0.124793\n",
      "12                  Violence/suicide         0.123426\n",
      "13    InjuryHx.PupilsBaselineDerived         0.107776\n",
      "14  InjuryHx.EDComplEventHypotension         0.050873\n",
      "15      InjuryHx.EDComplEventHypoxia         0.049245\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: BIRCH\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.023310\n",
      "1                               dim1         0.177299\n",
      "2                               Fall         0.008912\n",
      "3                                RTA         0.013409\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.020487\n",
      "5                               dim2         0.164504\n",
      "6                               dim3         0.061549\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.016013\n",
      "8                               dim4         0.108079\n",
      "9   InjuryHx.MajorExtracranialInjury         0.002959\n",
      "10                             Other         0.001164\n",
      "11                  Violence/suicide         0.001772\n",
      "12    InjuryHx.PupilsBaselineDerived         0.010385\n",
      "13  InjuryHx.EDComplEventHypotension         0.001804\n",
      "14      InjuryHx.EDComplEventHypoxia         0.001510\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: AgglomerativeClustering\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.002177\n",
      "1                               dim1         0.003055\n",
      "2                               Fall         0.000607\n",
      "3                                RTA         0.000357\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.001242\n",
      "5                               dim2         0.003854\n",
      "6                               dim3         0.004521\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.000596\n",
      "8                               dim4         0.026758\n",
      "9   InjuryHx.MajorExtracranialInjury         0.000223\n",
      "10                             Other         0.000296\n",
      "11                  Violence/suicide         0.000107\n",
      "12    InjuryHx.PupilsBaselineDerived         0.000338\n",
      "13  InjuryHx.EDComplEventHypotension         0.000290\n",
      "14      InjuryHx.EDComplEventHypoxia         0.000102\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: DBSCAN\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.087116\n",
      "1                               dim1         0.462743\n",
      "2                               Fall         0.286430\n",
      "3                                RTA         0.255722\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.202730\n",
      "5                               dim2         0.196678\n",
      "6                               dim3         0.142694\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.203769\n",
      "8                               dim4         0.164725\n",
      "9   InjuryHx.MajorExtracranialInjury         0.111744\n",
      "10                             Other         0.073005\n",
      "11                  Violence/suicide         0.058817\n",
      "12    InjuryHx.PupilsBaselineDerived         0.051341\n",
      "13  InjuryHx.EDComplEventHypotension         0.032887\n",
      "14      InjuryHx.EDComplEventHypoxia         0.027035\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: GaussianMixture\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.042552\n",
      "1                               dim1         0.419016\n",
      "2                               Fall         0.578722\n",
      "3                                RTA         0.572682\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.371026\n",
      "5                               dim2         0.230308\n",
      "6                               dim3         0.132523\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.397962\n",
      "8                               dim4         0.099555\n",
      "9   InjuryHx.MajorExtracranialInjury         0.160715\n",
      "10                             Other         0.181737\n",
      "11                  Violence/suicide         0.143631\n",
      "12    InjuryHx.PupilsBaselineDerived         0.181833\n",
      "13  InjuryHx.EDComplEventHypotension         0.112768\n",
      "14      InjuryHx.EDComplEventHypoxia         0.138986\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Ward\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.008255\n",
      "1                               dim1         0.141661\n",
      "2                               Fall         0.003579\n",
      "3                                RTA         0.002787\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.132989\n",
      "5                               dim2         0.102860\n",
      "6                               dim3         0.058116\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.292289\n",
      "8                               dim4         0.078218\n",
      "9   InjuryHx.MajorExtracranialInjury         0.007268\n",
      "10                             Other         0.001301\n",
      "11                  Violence/suicide         0.001273\n",
      "12    InjuryHx.PupilsBaselineDerived         0.020107\n",
      "13  InjuryHx.EDComplEventHypotension         0.004455\n",
      "14      InjuryHx.EDComplEventHypoxia         0.008405\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KMeans\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.532809\n",
      "1                               dim1         0.357313\n",
      "2                               Fall         0.075153\n",
      "3                                RTA         0.051878\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.268495\n",
      "5                               dim2         0.228533\n",
      "6                               dim3         0.304868\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.257877\n",
      "8                               dim4         0.147507\n",
      "9   InjuryHx.MajorExtracranialInjury         0.020956\n",
      "10                             Other         0.005264\n",
      "11                  Violence/suicide         0.008740\n",
      "12    InjuryHx.PupilsBaselineDerived         0.021342\n",
      "13  InjuryHx.EDComplEventHypotension         0.006245\n",
      "14      InjuryHx.EDComplEventHypoxia         0.006062\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KMedoids\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.592024\n",
      "1                               dim1         0.371762\n",
      "2                               Fall         0.274104\n",
      "3                                RTA         0.187454\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.239218\n",
      "5                               dim2         0.298866\n",
      "6                               dim3         0.193463\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.307245\n",
      "8                               dim4         0.112809\n",
      "9   InjuryHx.MajorExtracranialInjury         0.014219\n",
      "10                             Other         0.014479\n",
      "11                  Violence/suicide         0.016655\n",
      "12    InjuryHx.PupilsBaselineDerived         0.013666\n",
      "13  InjuryHx.EDComplEventHypotension         0.006038\n",
      "14      InjuryHx.EDComplEventHypoxia         0.006909\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: MeanShift\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.010959\n",
      "1                               dim1         0.009546\n",
      "2                               Fall         0.003202\n",
      "3                                RTA         0.003306\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.003734\n",
      "5                               dim2         0.026645\n",
      "6                               dim3         0.024626\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.002995\n",
      "8                               dim4         0.084545\n",
      "9   InjuryHx.MajorExtracranialInjury         0.001202\n",
      "10                             Other         0.000502\n",
      "11                  Violence/suicide         0.000669\n",
      "12    InjuryHx.PupilsBaselineDerived         0.001837\n",
      "13  InjuryHx.EDComplEventHypotension         0.000605\n",
      "14      InjuryHx.EDComplEventHypoxia         0.001088\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SpectralClustering\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.072588\n",
      "1                               dim1         0.026606\n",
      "2                               Fall         0.012436\n",
      "3                                RTA         0.033990\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.025515\n",
      "5                               dim2         0.029374\n",
      "6                               dim3         0.022654\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.005374\n",
      "8                               dim4         0.053558\n",
      "9   InjuryHx.MajorExtracranialInjury         0.007361\n",
      "10                             Other         0.002990\n",
      "11                  Violence/suicide         0.002788\n",
      "12    InjuryHx.PupilsBaselineDerived         0.001719\n",
      "13  InjuryHx.EDComplEventHypotension         0.001204\n",
      "14      InjuryHx.EDComplEventHypoxia         0.000955\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: OPTICS\n",
      "                             feature  mean_shap_value\n",
      "0                        Subject.Age         0.596051\n",
      "1                               dim1         0.320815\n",
      "2                               Fall         0.263006\n",
      "3                                RTA         0.184922\n",
      "4   InjuryHx.GCSScoreBaselineDerived         0.323626\n",
      "5                               dim2         0.215097\n",
      "6                               dim3         0.166834\n",
      "7   InjuryHx.GCSMotorBaselineDerived         0.200644\n",
      "8                               dim4         0.153960\n",
      "9   InjuryHx.MajorExtracranialInjury         0.112363\n",
      "10                             Other         0.072878\n",
      "11                  Violence/suicide         0.055765\n",
      "12    InjuryHx.PupilsBaselineDerived         0.044636\n",
      "13  InjuryHx.EDComplEventHypotension         0.029649\n",
      "14      InjuryHx.EDComplEventHypoxia         0.028517\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def shap_feature_ranking(data, shap_values, columns=[]):\n",
    "    if not columns: columns = data.columns.tolist()\n",
    "\n",
    "    c_idxs = []\n",
    "    for column in columns:\n",
    "        c_idxs.append(data.columns.get_loc(column))\n",
    "    if isinstance(shap_values, list):\n",
    "        means = [\n",
    "            np.abs(shap_values[class_][:, c_idxs]).mean(axis=0)\n",
    "            for class_ in range(len(shap_values))\n",
    "        ]\n",
    "        shap_means = np.sum(np.column_stack(means), 1)\n",
    "    else:\n",
    "        assert len(shap_values.shape\n",
    "                   ) == 2, 'Expected two-dimensional shap values array.'\n",
    "        shap_means = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    df_ranking = pd.DataFrame({\n",
    "        'feature': columns,\n",
    "        'mean_shap_value': shap_means\n",
    "    }).sort_values(by='mean_shap_value',\n",
    "                   ascending=False).reset_index(drop=True)\n",
    "    df_ranking.index += 1\n",
    "\n",
    "    return df_ranking\n",
    "\n",
    "\n",
    "y1 = cluster_labels['AffinityPropagation']\n",
    "y2 = cluster_labels['BIRCH']\n",
    "y3 = cluster_labels['AgglomerativeClustering']\n",
    "y4 = cluster_labels['DBSCAN']\n",
    "y5 = cluster_labels['GaussianMixture']\n",
    "y6 = cluster_labels['Ward']\n",
    "y7 = cluster_labels['KMeans']\n",
    "y8 = cluster_labels['KMedoids']\n",
    "y9 = cluster_labels['Mean Shift']\n",
    "y10 = cluster_labels['SpectralClustering']\n",
    "y11 = cluster_labels['OPTICS']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "cluster_labels_list = [(y1, 'AffinityPropagation'), (y2, 'BIRCH'),\n",
    "                       (y3, 'AgglomerativeClustering'), (y4, 'DBSCAN'),\n",
    "                       (y5, 'GaussianMixture'), (y6, 'Ward'), (y7, 'KMeans'),\n",
    "                       (y8, 'KMedoids'), (y9, 'MeanShift'),\n",
    "                       (y10, 'SpectralClustering'), (y11, 'OPTICS')]\n",
    "\n",
    "all_models = pd.DataFrame()\n",
    "\n",
    "# Perform SHAP analysis for each cluster label\n",
    "for i, (cluster_label, label_name) in enumerate(cluster_labels_list, start=1):\n",
    "    # Create and fit the RandomForestClassifier\n",
    "    clf.fit(cluster_vars_encoded_scaled, cluster_label)\n",
    "\n",
    "    # Create a TreeExplainer\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "    # Calculate SHAP values for all samples\n",
    "    shap_values = explainer.shap_values(cluster_vars_encoded_scaled)\n",
    "\n",
    "    # Get the feature ranking\n",
    "    feature_ranking = shap_feature_ranking(cluster_vars_encoded_scaled,\n",
    "                                           shap_values)\n",
    "\n",
    "    # Align feature order based on the first model's order\n",
    "    if i == 1:\n",
    "        feature_order = feature_ranking['feature'].tolist()\n",
    "    else:\n",
    "        feature_ranking = feature_ranking.set_index('feature').reindex(\n",
    "            feature_order).reset_index()\n",
    "\n",
    "    # Append the feature ranking to the final dataframe\n",
    "    all_models = pd.concat([all_models, feature_ranking], ignore_index=True)\n",
    "\n",
    "    # Print the model name\n",
    "    print(f'Model: {label_name}')\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(feature_ranking)\n",
    "    print('\\n' + '-' * 50 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bab549",
   "metadata": {},
   "source": [
    "## Scenario 2: Prognostic Value & Stability Bootstrap\n",
    "<a class=\"anchor\" id=\"chapter14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27252a8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: KMeans\n",
      "Optimism Average: 0.06346770092472759\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.46053207966413817\n",
      "Confidence Interval: [0.34655016890271123, 0.5745139904255652]\n",
      "Rand             0.980222\n",
      "Adjusted Rand    0.938192\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: KMedoids\n",
      "Optimism Average: 0.07655263220808141\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.44744714838078437\n",
      "Confidence Interval: [0.32646033610066383, 0.5684339606609049]\n",
      "Rand             0.893729\n",
      "Adjusted Rand    0.550165\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: GaussianMixture\n",
      "Optimism Average: 0.02947600149644679\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.49452377909241896\n",
      "Confidence Interval: [0.44162276991120336, 0.5474247882736346]\n",
      "Rand             0.955685\n",
      "Adjusted Rand    0.706549\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: AgglomerativeClustering\n",
      "Optimism Average: 0.00464992815268458\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.5193498524361811\n",
      "Confidence Interval: [0.5166966070849894, 0.5220030977873729]\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: Ward\n",
      "Optimism Average: 0.15794801188267274\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.36605176870619305\n",
      "Confidence Interval: [0.3551631635257689, 0.3769403738866172]\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: SpectralClustering\n",
      "Optimism Average: 0.004213129624227157\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.5197866509646386\n",
      "Confidence Interval: [0.5053939945940215, 0.5341793073352558]\n",
      "Rand             0.966343\n",
      "Adjusted Rand    0.821625\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: BIRCH\n",
      "Optimism Average: 0.13652497600054683\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.38747480458831896\n",
      "Confidence Interval: [0.3665339033872205, 0.4084157057894174]\n",
      "Rand             0.818906\n",
      "Adjusted Rand    0.622887\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: Mean Shift\n",
      "Optimism Average: 0.05015903129872497\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.4738407492901408\n",
      "Confidence Interval: [0.42340166357985437, 0.5242798350004273]\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: AffinityPropagation\n",
      "Optimism Average: 0.012741813148619774\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.511257967440246\n",
      "Confidence Interval: [0.4969021832305179, 0.5256137516499741]\n",
      "Rand             0.989113\n",
      "Adjusted Rand    0.412346\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: DBSCAN\n",
      "Optimism Average: 0.12679450754453095\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.39720527304433484\n",
      "Confidence Interval: [0.3754032946457851, 0.4190072514428846]\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "\n",
      "Algorithm: OPTICS\n",
      "Optimism Average: 0.04304925558169579\n",
      "AUC Apparent: 0.5239997805888658\n",
      "AUC Optimism Adjusted: 0.48095052500716995\n",
      "Confidence Interval: [0.4343785625424679, 0.527522487471872]\n",
      "Rand             1.0\n",
      "Adjusted Rand    1.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_data = pd.concat([y_dich, cluster_vars_encoded_scaled], axis=1)\n",
    "orig_data.columns = ['y_orig'] + list(cluster_vars_encoded_scaled.columns)\n",
    "\n",
    "# (1) AUC Apparent\n",
    "aucs_apparent = {}\n",
    "\n",
    "for algorithm_name, labels in cluster_labels.items():\n",
    "    df = pd.DataFrame({\"y_orig\": np.ravel(y_dich), \"labels\": np.ravel(labels)})\n",
    "    formula = \"y_orig ~ labels\"\n",
    "    model = sm.formula.glm(formula=formula, family=sm.families.Binomial(), data=df).fit()\n",
    "    y_pred_apparent = model.predict(df['labels'])\n",
    "    \n",
    "    aucs_apparent[algorithm_name] = auc_apparent\n",
    "    \n",
    "for algorithm_name, algorithm in clustering_algorithms:\n",
    "    \n",
    "    n_bootstraps = 10\n",
    "    aucs_bootstrap = []\n",
    "    optimisms = []\n",
    "    labels_origs = pd.DataFrame()\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        sample = resample(orig_data, replace=True, n_samples=4509)\n",
    "\n",
    "        y_boot = sample.iloc[:,0]\n",
    "        \n",
    "        # (2) AUC Bootstrap\n",
    "        try:\n",
    "            algorithm.fit(sample.iloc[:,1:])\n",
    "            if hasattr(algorithm, 'labels_'):\n",
    "                labels_boot = pd.DataFrame(algorithm.labels_)\n",
    "            elif hasattr(algorithm, 'predict'):\n",
    "                labels_boot = pd.DataFrame(algorithm.predict(sample.iloc[:,1:]))\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", str(e))\n",
    "            continue\n",
    "        \n",
    "        boot_data = pd.DataFrame({\"y_boot\": np.ravel(y_boot), \"labels_boot\": np.ravel(labels_boot)})\n",
    "\n",
    "        model = sm.formula.glm(formula=\"y_boot ~ labels_boot\", family=sm.families.Binomial(), data=boot_data).fit()\n",
    "\n",
    "        y_pred_boot = model.predict(labels_boot) # Probabilties between 0 / 1\n",
    "\n",
    "        auc_bootstrap = roc_auc_score(y_boot, y_pred_boot)\n",
    "        \n",
    "        aucs_bootstrap.append(auc_bootstrap)\n",
    "        \n",
    "        # (3) AUC Original \n",
    "        if isinstance(algorithm, (AgglomerativeClustering, SpectralClustering, MeanShift, DBSCAN, OPTICS)):\n",
    "            labels_orig = pd.DataFrame(algorithm.fit_predict(orig_data.iloc[:,1:]))\n",
    "        else:\n",
    "            labels_orig = pd.DataFrame(algorithm.predict(orig_data.iloc[:,1:]))\n",
    "\n",
    "        y_pred_orig = model.predict(labels_orig)\n",
    "\n",
    "        auc_original = roc_auc_score(df['y_orig'], y_pred_orig)\n",
    "        \n",
    "        optimism = auc_bootstrap - auc_original\n",
    "\n",
    "        optimisms.append(optimism)\n",
    "        \n",
    "        #\n",
    "        \n",
    "        labels_origs = pd.concat([labels_origs, labels_orig], axis=1)\n",
    "     \n",
    "    optimism_avg = np.mean(optimisms) # Should be positive\n",
    "    \n",
    "    aucs_o = aucs_apparent[algorithm_name] - optimism_avg\n",
    "    \n",
    "    ci = [aucs_o - 1.96 * np.std(aucs_bootstrap), aucs_o + 1.96 * np.std(aucs_bootstrap)]\n",
    "        \n",
    "    print(f\"Algorithm: {algorithm_name}\\n\"\n",
    "      f\"Optimism Average: {optimism_avg}\\n\"\n",
    "      f\"AUC Apparent: {aucs_apparent[algorithm_name]}\\n\"\n",
    "      f\"AUC Optimism Adjusted: {aucs_o}\\n\"\n",
    "      f\"Confidence Interval: {ci}\")\n",
    "\n",
    "    # Stability\n",
    "    \n",
    "    stability_bootstrap(labels_origs, n_bootstraps)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe837f",
   "metadata": {},
   "source": [
    "##  Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72cb0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_vectors(c):\n",
    "    v = [[], []]\n",
    "\n",
    "    for i, row in enumerate(c):\n",
    "        for j, val in enumerate(row):\n",
    "            v[0].extend([i] * val)\n",
    "            v[1].extend([j] * val)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc831feb",
   "metadata": {},
   "source": [
    "## Agreement: Pair-Confusion Matrix <a class=\"anchor\" id=\"chapter15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50d00fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rand</th>\n",
       "      <th>Adjusted Rand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AffinityPropagation_DBSCAN</th>\n",
       "      <td>0.688244</td>\n",
       "      <td>0.024650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AffinityPropagation_OPTICS</th>\n",
       "      <td>0.658632</td>\n",
       "      <td>-0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_AffinityPropagation</th>\n",
       "      <td>0.027705</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_BIRCH</th>\n",
       "      <td>0.764439</td>\n",
       "      <td>0.095943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_DBSCAN</th>\n",
       "      <td>0.314741</td>\n",
       "      <td>-0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_Mean Shift</th>\n",
       "      <td>0.953608</td>\n",
       "      <td>0.403054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_OPTICS</th>\n",
       "      <td>0.337574</td>\n",
       "      <td>-0.006076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_SpectralClustering</th>\n",
       "      <td>0.894069</td>\n",
       "      <td>-0.013953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_Ward</th>\n",
       "      <td>0.627201</td>\n",
       "      <td>0.032033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_AffinityPropagation</th>\n",
       "      <td>0.263014</td>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_DBSCAN</th>\n",
       "      <td>0.342564</td>\n",
       "      <td>-0.111719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_Mean Shift</th>\n",
       "      <td>0.799849</td>\n",
       "      <td>0.294113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_OPTICS</th>\n",
       "      <td>0.368379</td>\n",
       "      <td>-0.086742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBSCAN_OPTICS</th>\n",
       "      <td>0.788575</td>\n",
       "      <td>0.518993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_AffinityPropagation</th>\n",
       "      <td>0.929672</td>\n",
       "      <td>0.159102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_AgglomerativeClustering</th>\n",
       "      <td>0.090240</td>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_BIRCH</th>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.031115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_DBSCAN</th>\n",
       "      <td>0.716830</td>\n",
       "      <td>0.174381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_Mean Shift</th>\n",
       "      <td>0.135179</td>\n",
       "      <td>0.008218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_OPTICS</th>\n",
       "      <td>0.628844</td>\n",
       "      <td>-0.029718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_SpectralClustering</th>\n",
       "      <td>0.153408</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_Ward</th>\n",
       "      <td>0.440275</td>\n",
       "      <td>0.068960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_AffinityPropagation</th>\n",
       "      <td>0.805296</td>\n",
       "      <td>0.067464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_AgglomerativeClustering</th>\n",
       "      <td>0.218964</td>\n",
       "      <td>0.008583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_BIRCH</th>\n",
       "      <td>0.432101</td>\n",
       "      <td>0.122962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_DBSCAN</th>\n",
       "      <td>0.609547</td>\n",
       "      <td>-0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_GaussianMixture</th>\n",
       "      <td>0.790308</td>\n",
       "      <td>0.149254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_KMedoids</th>\n",
       "      <td>0.856285</td>\n",
       "      <td>0.498987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_Mean Shift</th>\n",
       "      <td>0.264672</td>\n",
       "      <td>0.032682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_OPTICS</th>\n",
       "      <td>0.569390</td>\n",
       "      <td>-0.070123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_SpectralClustering</th>\n",
       "      <td>0.267132</td>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_Ward</th>\n",
       "      <td>0.557772</td>\n",
       "      <td>0.225205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_AffinityPropagation</th>\n",
       "      <td>0.865883</td>\n",
       "      <td>0.105495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_AgglomerativeClustering</th>\n",
       "      <td>0.153933</td>\n",
       "      <td>-0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_BIRCH</th>\n",
       "      <td>0.365895</td>\n",
       "      <td>0.063823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_DBSCAN</th>\n",
       "      <td>0.671674</td>\n",
       "      <td>0.107767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_GaussianMixture</th>\n",
       "      <td>0.847053</td>\n",
       "      <td>0.216625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_Mean Shift</th>\n",
       "      <td>0.189565</td>\n",
       "      <td>0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_OPTICS</th>\n",
       "      <td>0.618315</td>\n",
       "      <td>0.002564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_SpectralClustering</th>\n",
       "      <td>0.208676</td>\n",
       "      <td>0.002036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_Ward</th>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.135350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_AffinityPropagation</th>\n",
       "      <td>0.074078</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_DBSCAN</th>\n",
       "      <td>0.313469</td>\n",
       "      <td>-0.038404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_OPTICS</th>\n",
       "      <td>0.343122</td>\n",
       "      <td>-0.021237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_AffinityPropagation</th>\n",
       "      <td>0.100566</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_BIRCH</th>\n",
       "      <td>0.747554</td>\n",
       "      <td>0.150757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_DBSCAN</th>\n",
       "      <td>0.350529</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_Mean Shift</th>\n",
       "      <td>0.936217</td>\n",
       "      <td>0.552216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_OPTICS</th>\n",
       "      <td>0.386016</td>\n",
       "      <td>0.031789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_AffinityPropagation</th>\n",
       "      <td>0.391940</td>\n",
       "      <td>0.013251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_BIRCH</th>\n",
       "      <td>0.780656</td>\n",
       "      <td>0.502760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_DBSCAN</th>\n",
       "      <td>0.417354</td>\n",
       "      <td>-0.071373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_Mean Shift</th>\n",
       "      <td>0.652091</td>\n",
       "      <td>0.121802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_OPTICS</th>\n",
       "      <td>0.399638</td>\n",
       "      <td>-0.113935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_SpectralClustering</th>\n",
       "      <td>0.618386</td>\n",
       "      <td>0.052460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Rand  Adjusted Rand\n",
       "AffinityPropagation_DBSCAN                   0.688244       0.024650\n",
       "AffinityPropagation_OPTICS                   0.658632      -0.004921\n",
       "AgglomerativeClustering_AffinityPropagation  0.027705       0.000378\n",
       "AgglomerativeClustering_BIRCH                0.764439       0.095943\n",
       "AgglomerativeClustering_DBSCAN               0.314741      -0.010331\n",
       "AgglomerativeClustering_Mean Shift           0.953608       0.403054\n",
       "AgglomerativeClustering_OPTICS               0.337574      -0.006076\n",
       "AgglomerativeClustering_SpectralClustering   0.894069      -0.013953\n",
       "AgglomerativeClustering_Ward                 0.627201       0.032033\n",
       "BIRCH_AffinityPropagation                    0.263014       0.007129\n",
       "BIRCH_DBSCAN                                 0.342564      -0.111719\n",
       "BIRCH_Mean Shift                             0.799849       0.294113\n",
       "BIRCH_OPTICS                                 0.368379      -0.086742\n",
       "DBSCAN_OPTICS                                0.788575       0.518993\n",
       "GaussianMixture_AffinityPropagation          0.929672       0.159102\n",
       "GaussianMixture_AgglomerativeClustering      0.090240       0.001895\n",
       "GaussianMixture_BIRCH                        0.311200       0.031115\n",
       "GaussianMixture_DBSCAN                       0.716830       0.174381\n",
       "GaussianMixture_Mean Shift                   0.135179       0.008218\n",
       "GaussianMixture_OPTICS                       0.628844      -0.029718\n",
       "GaussianMixture_SpectralClustering           0.153408       0.002151\n",
       "GaussianMixture_Ward                         0.440275       0.068960\n",
       "KMeans_AffinityPropagation                   0.805296       0.067464\n",
       "KMeans_AgglomerativeClustering               0.218964       0.008583\n",
       "KMeans_BIRCH                                 0.432101       0.122962\n",
       "KMeans_DBSCAN                                0.609547      -0.000704\n",
       "KMeans_GaussianMixture                       0.790308       0.149254\n",
       "KMeans_KMedoids                              0.856285       0.498987\n",
       "KMeans_Mean Shift                            0.264672       0.032682\n",
       "KMeans_OPTICS                                0.569390      -0.070123\n",
       "KMeans_SpectralClustering                    0.267132       0.014547\n",
       "KMeans_Ward                                  0.557772       0.225205\n",
       "KMedoids_AffinityPropagation                 0.865883       0.105495\n",
       "KMedoids_AgglomerativeClustering             0.153933      -0.000120\n",
       "KMedoids_BIRCH                               0.365895       0.063823\n",
       "KMedoids_DBSCAN                              0.671674       0.107767\n",
       "KMedoids_GaussianMixture                     0.847053       0.216625\n",
       "KMedoids_Mean Shift                          0.189565       0.002854\n",
       "KMedoids_OPTICS                              0.618315       0.002564\n",
       "KMedoids_SpectralClustering                  0.208676       0.002036\n",
       "KMedoids_Ward                                0.494118       0.135350\n",
       "Mean Shift_AffinityPropagation               0.074078       0.001475\n",
       "Mean Shift_DBSCAN                            0.313469      -0.038404\n",
       "Mean Shift_OPTICS                            0.343122      -0.021237\n",
       "SpectralClustering_AffinityPropagation       0.100566       0.000868\n",
       "SpectralClustering_BIRCH                     0.747554       0.150757\n",
       "SpectralClustering_DBSCAN                    0.350529       0.002242\n",
       "SpectralClustering_Mean Shift                0.936217       0.552216\n",
       "SpectralClustering_OPTICS                    0.386016       0.031789\n",
       "Ward_AffinityPropagation                     0.391940       0.013251\n",
       "Ward_BIRCH                                   0.780656       0.502760\n",
       "Ward_DBSCAN                                  0.417354      -0.071373\n",
       "Ward_Mean Shift                              0.652091       0.121802\n",
       "Ward_OPTICS                                  0.399638      -0.113935\n",
       "Ward_SpectralClustering                      0.618386       0.052460"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agreement_pairconf(cluster_labels):\n",
    "\n",
    "    rands = []\n",
    "    arands = []\n",
    "    names = []\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    cluster_labels = pd.DataFrame.from_dict(cluster_labels)\n",
    "\n",
    "    # Get all pairwise combinations of the columns\n",
    "    pairwise_combinations = pd.DataFrame(\n",
    "        list(combinations(cluster_labels.columns, 2)))\n",
    "\n",
    "    # Iterate over all pairwise combinations\n",
    "    for i in range(len(pairwise_combinations)):\n",
    "\n",
    "        pairconf = pair_confusion_matrix(\n",
    "            cluster_labels[pairwise_combinations.iloc[i, 0]],\n",
    "            cluster_labels[pairwise_combinations.iloc[i, 1]])\n",
    "\n",
    "        a = pairconf[1, 1]  # pairs grouped together in both\n",
    "        b = pairconf[1, 0]\n",
    "        c = pairconf[0, 1]\n",
    "        d = pairconf[0, 0]  # pairs not grouped together in both\n",
    "\n",
    "        rand = (a + d) / (a + d + b + c)\n",
    "        arand = 2 * (a * d - b * c) / ((a + b) * (d + b) + (a + c) * (d + c))\n",
    "\n",
    "        rands.append(rand)\n",
    "        arands.append(arand)\n",
    "\n",
    "        names.append(\n",
    "            f\"{pairwise_combinations.iloc[i,0]}_{pairwise_combinations.iloc[i,1]}\"\n",
    "        )\n",
    "\n",
    "    scores = pd.DataFrame({\n",
    "        'Rand': rands,\n",
    "        'Adjusted Rand': arands\n",
    "    },\n",
    "                          index=names)\n",
    "\n",
    "    return scores.sort_index(\n",
    "    )  # scores.sort_values('Adjusted Rand', ascending=False)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "agreement_pairconf(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d1e3e",
   "metadata": {},
   "source": [
    "## Agreement: Contingency Table <a class=\"anchor\" id=\"chapter16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f212bf0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Adjusted Mutual Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AffinityPropagation_DBSCAN</th>\n",
       "      <td>1.490757</td>\n",
       "      <td>0.323935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AffinityPropagation_OPTICS</th>\n",
       "      <td>1.996757</td>\n",
       "      <td>0.253495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_AffinityPropagation</th>\n",
       "      <td>0.048644</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_BIRCH</th>\n",
       "      <td>0.048644</td>\n",
       "      <td>0.194965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_DBSCAN</th>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.002524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_Mean Shift</th>\n",
       "      <td>0.048644</td>\n",
       "      <td>0.443940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_OPTICS</th>\n",
       "      <td>0.012313</td>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_SpectralClustering</th>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgglomerativeClustering_Ward</th>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.037154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_AffinityPropagation</th>\n",
       "      <td>0.402027</td>\n",
       "      <td>0.123193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_DBSCAN</th>\n",
       "      <td>0.107989</td>\n",
       "      <td>0.085053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_Mean Shift</th>\n",
       "      <td>0.097808</td>\n",
       "      <td>0.313732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRCH_OPTICS</th>\n",
       "      <td>0.130891</td>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBSCAN_OPTICS</th>\n",
       "      <td>1.303874</td>\n",
       "      <td>0.472834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_AffinityPropagation</th>\n",
       "      <td>2.165683</td>\n",
       "      <td>0.438493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_AgglomerativeClustering</th>\n",
       "      <td>0.026076</td>\n",
       "      <td>0.015341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_BIRCH</th>\n",
       "      <td>0.177588</td>\n",
       "      <td>0.100932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_DBSCAN</th>\n",
       "      <td>1.299326</td>\n",
       "      <td>0.514325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_Mean Shift</th>\n",
       "      <td>0.093303</td>\n",
       "      <td>0.052788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_OPTICS</th>\n",
       "      <td>1.081272</td>\n",
       "      <td>0.252169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_SpectralClustering</th>\n",
       "      <td>0.115474</td>\n",
       "      <td>0.060562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianMixture_Ward</th>\n",
       "      <td>0.327145</td>\n",
       "      <td>0.184998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_AffinityPropagation</th>\n",
       "      <td>1.513145</td>\n",
       "      <td>0.390842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_AgglomerativeClustering</th>\n",
       "      <td>0.048644</td>\n",
       "      <td>0.053031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_BIRCH</th>\n",
       "      <td>0.293136</td>\n",
       "      <td>0.264755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_DBSCAN</th>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_GaussianMixture</th>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.279058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_KMedoids</th>\n",
       "      <td>1.133319</td>\n",
       "      <td>0.600135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_Mean Shift</th>\n",
       "      <td>0.151605</td>\n",
       "      <td>0.153350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_OPTICS</th>\n",
       "      <td>0.631990</td>\n",
       "      <td>0.213862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_SpectralClustering</th>\n",
       "      <td>0.135554</td>\n",
       "      <td>0.129393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeans_Ward</th>\n",
       "      <td>0.379268</td>\n",
       "      <td>0.325670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_AffinityPropagation</th>\n",
       "      <td>1.695466</td>\n",
       "      <td>0.424432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_AgglomerativeClustering</th>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.003780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_BIRCH</th>\n",
       "      <td>0.230806</td>\n",
       "      <td>0.186493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_DBSCAN</th>\n",
       "      <td>0.681934</td>\n",
       "      <td>0.334618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_GaussianMixture</th>\n",
       "      <td>0.843711</td>\n",
       "      <td>0.332835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_Mean Shift</th>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.021598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_OPTICS</th>\n",
       "      <td>0.804744</td>\n",
       "      <td>0.267339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_SpectralClustering</th>\n",
       "      <td>0.064798</td>\n",
       "      <td>0.051847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMedoids_Ward</th>\n",
       "      <td>0.353170</td>\n",
       "      <td>0.273168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_AffinityPropagation</th>\n",
       "      <td>0.164715</td>\n",
       "      <td>0.043922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_DBSCAN</th>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.010520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Shift_OPTICS</th>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.008935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_AffinityPropagation</th>\n",
       "      <td>0.223617</td>\n",
       "      <td>0.052925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_BIRCH</th>\n",
       "      <td>0.050273</td>\n",
       "      <td>0.137951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_DBSCAN</th>\n",
       "      <td>0.068839</td>\n",
       "      <td>0.049087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_Mean Shift</th>\n",
       "      <td>0.104655</td>\n",
       "      <td>0.479669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpectralClustering_OPTICS</th>\n",
       "      <td>0.178565</td>\n",
       "      <td>0.082728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_AffinityPropagation</th>\n",
       "      <td>0.523320</td>\n",
       "      <td>0.166011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_BIRCH</th>\n",
       "      <td>0.200148</td>\n",
       "      <td>0.393105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_DBSCAN</th>\n",
       "      <td>0.202855</td>\n",
       "      <td>0.160335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_Mean Shift</th>\n",
       "      <td>0.045709</td>\n",
       "      <td>0.121084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_OPTICS</th>\n",
       "      <td>0.183098</td>\n",
       "      <td>0.090043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward_SpectralClustering</th>\n",
       "      <td>0.038528</td>\n",
       "      <td>0.090835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Mutual Information  \\\n",
       "AffinityPropagation_DBSCAN                             1.490757   \n",
       "AffinityPropagation_OPTICS                             1.996757   \n",
       "AgglomerativeClustering_AffinityPropagation            0.048644   \n",
       "AgglomerativeClustering_BIRCH                          0.048644   \n",
       "AgglomerativeClustering_DBSCAN                         0.005396   \n",
       "AgglomerativeClustering_Mean Shift                     0.048644   \n",
       "AgglomerativeClustering_OPTICS                         0.012313   \n",
       "AgglomerativeClustering_SpectralClustering             0.000406   \n",
       "AgglomerativeClustering_Ward                           0.011583   \n",
       "BIRCH_AffinityPropagation                              0.402027   \n",
       "BIRCH_DBSCAN                                           0.107989   \n",
       "BIRCH_Mean Shift                                       0.097808   \n",
       "BIRCH_OPTICS                                           0.130891   \n",
       "DBSCAN_OPTICS                                          1.303874   \n",
       "GaussianMixture_AffinityPropagation                    2.165683   \n",
       "GaussianMixture_AgglomerativeClustering                0.026076   \n",
       "GaussianMixture_BIRCH                                  0.177588   \n",
       "GaussianMixture_DBSCAN                                 1.299326   \n",
       "GaussianMixture_Mean Shift                             0.093303   \n",
       "GaussianMixture_OPTICS                                 1.081272   \n",
       "GaussianMixture_SpectralClustering                     0.115474   \n",
       "GaussianMixture_Ward                                   0.327145   \n",
       "KMeans_AffinityPropagation                             1.513145   \n",
       "KMeans_AgglomerativeClustering                         0.048644   \n",
       "KMeans_BIRCH                                           0.293136   \n",
       "KMeans_DBSCAN                                          0.500023   \n",
       "KMeans_GaussianMixture                                 0.675699   \n",
       "KMeans_KMedoids                                        1.133319   \n",
       "KMeans_Mean Shift                                      0.151605   \n",
       "KMeans_OPTICS                                          0.631990   \n",
       "KMeans_SpectralClustering                              0.135554   \n",
       "KMeans_Ward                                            0.379268   \n",
       "KMedoids_AffinityPropagation                           1.695466   \n",
       "KMedoids_AgglomerativeClustering                       0.004722   \n",
       "KMedoids_BIRCH                                         0.230806   \n",
       "KMedoids_DBSCAN                                        0.681934   \n",
       "KMedoids_GaussianMixture                               0.843711   \n",
       "KMedoids_Mean Shift                                    0.028512   \n",
       "KMedoids_OPTICS                                        0.804744   \n",
       "KMedoids_SpectralClustering                            0.064798   \n",
       "KMedoids_Ward                                          0.353170   \n",
       "Mean Shift_AffinityPropagation                         0.164715   \n",
       "Mean Shift_DBSCAN                                      0.021090   \n",
       "Mean Shift_OPTICS                                      0.044325   \n",
       "SpectralClustering_AffinityPropagation                 0.223617   \n",
       "SpectralClustering_BIRCH                               0.050273   \n",
       "SpectralClustering_DBSCAN                              0.068839   \n",
       "SpectralClustering_Mean Shift                          0.104655   \n",
       "SpectralClustering_OPTICS                              0.178565   \n",
       "Ward_AffinityPropagation                               0.523320   \n",
       "Ward_BIRCH                                             0.200148   \n",
       "Ward_DBSCAN                                            0.202855   \n",
       "Ward_Mean Shift                                        0.045709   \n",
       "Ward_OPTICS                                            0.183098   \n",
       "Ward_SpectralClustering                                0.038528   \n",
       "\n",
       "                                             Adjusted Mutual Information  \n",
       "AffinityPropagation_DBSCAN                                      0.323935  \n",
       "AffinityPropagation_OPTICS                                      0.253495  \n",
       "AgglomerativeClustering_AffinityPropagation                     0.012739  \n",
       "AgglomerativeClustering_BIRCH                                   0.194965  \n",
       "AgglomerativeClustering_DBSCAN                                  0.002524  \n",
       "AgglomerativeClustering_Mean Shift                              0.443940  \n",
       "AgglomerativeClustering_OPTICS                                  0.001887  \n",
       "AgglomerativeClustering_SpectralClustering                     -0.000770  \n",
       "AgglomerativeClustering_Ward                                    0.037154  \n",
       "BIRCH_AffinityPropagation                                       0.123193  \n",
       "BIRCH_DBSCAN                                                    0.085053  \n",
       "BIRCH_Mean Shift                                                0.313732  \n",
       "BIRCH_OPTICS                                                    0.056148  \n",
       "DBSCAN_OPTICS                                                   0.472834  \n",
       "GaussianMixture_AffinityPropagation                             0.438493  \n",
       "GaussianMixture_AgglomerativeClustering                         0.015341  \n",
       "GaussianMixture_BIRCH                                           0.100932  \n",
       "GaussianMixture_DBSCAN                                          0.514325  \n",
       "GaussianMixture_Mean Shift                                      0.052788  \n",
       "GaussianMixture_OPTICS                                          0.252169  \n",
       "GaussianMixture_SpectralClustering                              0.060562  \n",
       "GaussianMixture_Ward                                            0.184998  \n",
       "KMeans_AffinityPropagation                                      0.390842  \n",
       "KMeans_AgglomerativeClustering                                  0.053031  \n",
       "KMeans_BIRCH                                                    0.264755  \n",
       "KMeans_DBSCAN                                                   0.258700  \n",
       "KMeans_GaussianMixture                                          0.279058  \n",
       "KMeans_KMedoids                                                 0.600135  \n",
       "KMeans_Mean Shift                                               0.153350  \n",
       "KMeans_OPTICS                                                   0.213862  \n",
       "KMeans_SpectralClustering                                       0.129393  \n",
       "KMeans_Ward                                                     0.325670  \n",
       "KMedoids_AffinityPropagation                                    0.424432  \n",
       "KMedoids_AgglomerativeClustering                                0.003780  \n",
       "KMedoids_BIRCH                                                  0.186493  \n",
       "KMedoids_DBSCAN                                                 0.334618  \n",
       "KMedoids_GaussianMixture                                        0.332835  \n",
       "KMedoids_Mean Shift                                             0.021598  \n",
       "KMedoids_OPTICS                                                 0.267339  \n",
       "KMedoids_SpectralClustering                                     0.051847  \n",
       "KMedoids_Ward                                                   0.273168  \n",
       "Mean Shift_AffinityPropagation                                  0.043922  \n",
       "Mean Shift_DBSCAN                                               0.010520  \n",
       "Mean Shift_OPTICS                                               0.008935  \n",
       "SpectralClustering_AffinityPropagation                          0.052925  \n",
       "SpectralClustering_BIRCH                                        0.137951  \n",
       "SpectralClustering_DBSCAN                                       0.049087  \n",
       "SpectralClustering_Mean Shift                                   0.479669  \n",
       "SpectralClustering_OPTICS                                       0.082728  \n",
       "Ward_AffinityPropagation                                        0.166011  \n",
       "Ward_BIRCH                                                      0.393105  \n",
       "Ward_DBSCAN                                                     0.160335  \n",
       "Ward_Mean Shift                                                 0.121084  \n",
       "Ward_OPTICS                                                     0.090043  \n",
       "Ward_SpectralClustering                                         0.090835  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agreement_contingency(cluster_labels):\n",
    "    scores = {}\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    cluster_labels = pd.DataFrame.from_dict(cluster_labels)\n",
    "\n",
    "    # Get all pairwise combinations of the columns\n",
    "    pairwise_combinations = pd.DataFrame(\n",
    "        list(combinations(cluster_labels.columns, 2)))\n",
    "\n",
    "    # Iterate over all pairwise combinations\n",
    "    for i in range(len(pairwise_combinations)):\n",
    "        contingency = contingency_matrix(\n",
    "            cluster_labels[pairwise_combinations.iloc[i, 0]],\n",
    "            cluster_labels[pairwise_combinations.iloc[i, 1]])\n",
    "\n",
    "        mi = mutual_info_score(_, _, contingency=contingency)\n",
    "        ami = adjusted_mutual_info_score(\n",
    "            produce_vectors(contingency)[0],\n",
    "            produce_vectors(contingency)[1])\n",
    "\n",
    "        scores[pairwise_combinations.iloc[i, 0] + '_' +\n",
    "               pairwise_combinations.iloc[i, 1]] = {\n",
    "                   'Mutual Information': mi,\n",
    "                   'Adjusted Mutual Information': ami\n",
    "               }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    scores = pd.DataFrame.from_dict(scores, orient='index')\n",
    "\n",
    "    return scores.sort_index(\n",
    "    )  # scores.sort_values('Adjusted Mutual Information', ascending=False)\n",
    "\n",
    "\n",
    "agreement_contingency(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd49de8",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "source": [
    "## Input for the UpSet Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e534b1",
   "metadata": {
    "scrolled": false,
    "tags": [
     "no"
    ]
   },
   "outputs": [],
   "source": [
    "def binary_matrix(cluster_labels):\n",
    "\n",
    "    binary = []\n",
    "    data_dict = {}\n",
    "\n",
    "    for algorithm_name, labels in cluster_labels.items():\n",
    "        n = len(labels)\n",
    "        labels_repeated = labels.repeat(n).reshape(n, n)\n",
    "        labels_transposed = labels_repeated.transpose()\n",
    "        temp = (labels_repeated == labels_transposed).astype(int)\n",
    "        col = temp[np.triu_indices(labels_repeated.shape[0], k=1)].transpose()\n",
    "        binary.append(algorithm_name)\n",
    "        binary.append(col)\n",
    "\n",
    "    for i, item in enumerate(binary):\n",
    "        if i % 2 == 0:\n",
    "            # The item is a column name\n",
    "            col_name = item\n",
    "        else:\n",
    "            data_dict[col_name] = item\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "binary_matrix(cluster_labels)\n",
    "\n",
    "#\n",
    "\n",
    "N = len(next(iter(cluster_labels.values())))\n",
    "K = len(cluster_labels)\n",
    "\n",
    "# Convert labels dictionary to numpy array\n",
    "A = np.zeros((N, K))\n",
    "for i, label_list in enumerate(cluster_labels.values()):\n",
    "    A[:, i] = label_list\n",
    "\n",
    "# Create an array to store the group results for each algorithm\n",
    "group_results = []\n",
    "\n",
    "# Iterate over the algorithms\n",
    "for i, label_list in enumerate(cluster_labels.values()):\n",
    "    # Create an empty array to store the group results for the pairs\n",
    "    algorithm_group = np.zeros(N * (N - 1) // 2, dtype=int)\n",
    "    idx = 0\n",
    "    # Iterate over the data point pairs\n",
    "    for j in range(N):\n",
    "        for k in range(j + 1, N):\n",
    "            # Check if the algorithm groups the pair or not\n",
    "            if label_list[j] == label_list[k]:\n",
    "                algorithm_group[idx] = 1\n",
    "            idx += 1\n",
    "    group_results.append(algorithm_group)\n",
    "\n",
    "# Create a Pandas DataFrame with the group results\n",
    "df = pd.DataFrame(np.column_stack(group_results),\n",
    "                  columns=cluster_labels.keys())\n",
    "\n",
    "#\n",
    "\n",
    "# Convert pandas dataframe to R dataframe\n",
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_df = robjects.conversion.py2rpy(df)\n",
    "\n",
    "# Save R dataframe as .rds file\n",
    "r_file = \"M1_BinaryMatrix.rds\"\n",
    "robjects.r.assign(\"my_df_tosave\", r_df)\n",
    "robjects.r(f\"saveRDS(my_df_tosave, file='{r_file}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdf1d2",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "source": [
    "## 'Intersection' Bootstrap Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1e74c",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "outputs": [],
   "source": [
    "def stability_pairconf(data, algorithm, n_samples, n_iter=200):\n",
    "\n",
    "    labels = []\n",
    "    intersect = []\n",
    "\n",
    "    rands = []\n",
    "    arands = []\n",
    "\n",
    "    for x in range(n_iter):\n",
    "        boot = resample(data, replace=True, n_samples=n_samples)\n",
    "        algorithm = algorithm.fit(boot)\n",
    "        labels.append(boot.index)\n",
    "\n",
    "        if isinstance(algorithm, GaussianMixture):\n",
    "            labels.append(algorithm.predict(boot))\n",
    "        else:\n",
    "            labels.append(algorithm.labels_)\n",
    "\n",
    "    labels = np.array(labels).transpose()\n",
    "    labels = pd.DataFrame(labels)\n",
    "\n",
    "    for col_pos_1 in range(n_iter):\n",
    "        for col_pos_2 in range(col_pos_1 + 1, n_iter):\n",
    "            if col_pos_1 == col_pos_2:\n",
    "                continue\n",
    "\n",
    "            intersect = list(\n",
    "                set(labels[col_pos_1 * 2]) & set(labels[col_pos_2 * 2]))\n",
    "\n",
    "            run_1_pred = labels[[col_pos_1 * 2, col_pos_1 * 2 + 1\n",
    "                                 ]].loc[labels[col_pos_1 * 2].isin(intersect)]\n",
    "            run_2_pred = labels[[col_pos_2 * 2, col_pos_2 * 2 + 1\n",
    "                                 ]].loc[labels[col_pos_2 * 2].isin(intersect)]\n",
    "\n",
    "            run_1_pred = run_1_pred.sort_values(\n",
    "                by=col_pos_1 * 2).drop_duplicates(subset=[col_pos_1 * 2])\n",
    "            run_2_pred = run_2_pred.sort_values(\n",
    "                by=col_pos_2 * 2).drop_duplicates(subset=[col_pos_2 * 2])\n",
    "\n",
    "            run_1_pred = run_1_pred[col_pos_1 * 2 + 1]\n",
    "            run_2_pred = run_2_pred[col_pos_2 * 2 + 1]\n",
    "\n",
    "            pairconf = pair_confusion_matrix(run_1_pred, run_2_pred)\n",
    "\n",
    "            a = pairconf[1, 1]  # pairs grouped together in both\n",
    "            b = pairconf[1, 0]\n",
    "            c = pairconf[0, 1]\n",
    "            d = pairconf[0, 0]  # pairs not grouped together in both\n",
    "\n",
    "            rand = (a + d) / (a + d + b + c)\n",
    "            arand = 2 * (a * d - b * c) / ((a + b) * (d + b) + (a + c) *\n",
    "                                           (d + c))\n",
    "\n",
    "            rands.append(rand)\n",
    "            arands.append(arand)\n",
    "\n",
    "    scores = pd.DataFrame({'Rand': rands, 'Adjusted Rand': arands})\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each algorithm in clustering_algorithms\n",
    "for algorithm, algorithm_function in [\n",
    "        clustering_algorithms[3], clustering_algorithms[4],\n",
    "        clustering_algorithms[5], clustering_algorithms[7],\n",
    "        clustering_algorithms[9], clustering_algorithms[10]\n",
    "]:\n",
    "    print(algorithm_function)\n",
    "\n",
    "    # Call the stability_pairconf function with the appropriate parameters\n",
    "    result = stability_pairconf(cluster_vars_encoded_scaled,\n",
    "                                algorithm_function,\n",
    "                                n_samples=4509,\n",
    "                                n_iter=200)\n",
    "\n",
    "    # Assign a name to the row based on the algorithm\n",
    "    result.name = algorithm\n",
    "\n",
    "    # Append the result to the DataFrame\n",
    "    results_df = results_df.append(result)\n",
    "\n",
    "    # Print the intermediate result\n",
    "    print(f\"Algorithm: {algorithm}\")\n",
    "    print(result)\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(results_df)\n",
    "\n",
    "stability_pairconf(cluster_vars_encoded_scaled,\n",
    "                   OPTICS(),\n",
    "                   n_samples=4509,\n",
    "                   n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b174194",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "source": [
    "## 'Intersection' Bootstrap Gower's Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584bc535",
   "metadata": {
    "tags": [
     "no"
    ]
   },
   "outputs": [],
   "source": [
    "def stability_pairconf(data, algorithm, n_samples, n_iter):\n",
    "\n",
    "    labels = []\n",
    "    intersect = []\n",
    "\n",
    "    rands = []\n",
    "    arands = []\n",
    "\n",
    "    for x in range(n_iter):\n",
    "        boot = resample(data, replace=True, n_samples=n_samples)\n",
    "        labels.append(boot.index)\n",
    "        gowerdist = pd.DataFrame(gower.gower_matrix(boot))\n",
    "\n",
    "        if isinstance(algorithm, sklearn.cluster._spectral.SpectralClustering):\n",
    "            gowersim = 1 - gowerdist\n",
    "            algorithm = algorithm.fit(gowersim)\n",
    "            labels.append(algorithm.labels_)\n",
    "        else:\n",
    "            algorithm = algorithm.fit(gowerdist)\n",
    "            labels.append(algorithm.labels_)\n",
    "\n",
    "    labels = pd.DataFrame(np.array(labels).transpose())\n",
    "    print(labels)\n",
    "\n",
    "    for col_pos_1 in range(n_iter):\n",
    "        for col_pos_2 in range(col_pos_1 + 1, n_iter):\n",
    "            if col_pos_1 == col_pos_2:\n",
    "                continue\n",
    "\n",
    "            intersect = list(\n",
    "                set(labels[col_pos_1 * 2]) & set(labels[col_pos_2 * 2]))\n",
    "\n",
    "            run_1_pred = labels[[col_pos_1 * 2, col_pos_1 * 2 + 1\n",
    "                                 ]].loc[labels[col_pos_1 * 2].isin(intersect)]\n",
    "            run_2_pred = labels[[col_pos_2 * 2, col_pos_2 * 2 + 1\n",
    "                                 ]].loc[labels[col_pos_2 * 2].isin(intersect)]\n",
    "\n",
    "            run_1_pred = run_1_pred.sort_values(\n",
    "                by=col_pos_1 * 2).drop_duplicates(subset=[col_pos_1 * 2])\n",
    "            run_2_pred = run_2_pred.sort_values(\n",
    "                by=col_pos_2 * 2).drop_duplicates(subset=[col_pos_2 * 2])\n",
    "\n",
    "            run_1_pred = run_1_pred[col_pos_1 * 2 + 1]\n",
    "            run_2_pred = run_2_pred[col_pos_2 * 2 + 1]\n",
    "\n",
    "            pairconf = pair_confusion_matrix(run_1_pred, run_2_pred)\n",
    "\n",
    "            a = pairconf[1, 1]  # pairs grouped together in both\n",
    "            b = pairconf[1, 0]\n",
    "            c = pairconf[0, 1]\n",
    "            d = pairconf[0, 0]  # pairs not grouped together in both\n",
    "\n",
    "            rand = (a + d) / (a + d + b + c)\n",
    "            arand = 2 * (a * d - b * c) / ((a + b) * (d + b) + (a + c) *\n",
    "                                           (d + c))\n",
    "\n",
    "            rands.append(rand)\n",
    "            arands.append(arand)\n",
    "\n",
    "    scores = pd.DataFrame({'Rand': rands, 'Adjusted Rand': arands})\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for algorithm, algorithm_function in [\n",
    "        clustering_algorithms[6], clustering_algorithms[8],\n",
    "        clustering_algorithms[10]\n",
    "]:\n",
    "    print(algorithm_function)\n",
    "\n",
    "    result = stability_pairconf(cluster_vars_encoded,\n",
    "                                algorithm_function,\n",
    "                                n_samples=4509,\n",
    "                                n_iter=200)\n",
    "\n",
    "    result.name = algorithm\n",
    "\n",
    "    results_df = results_df.append(result)\n",
    "\n",
    "    print(f\"Algorithm: {algorithm}\")\n",
    "    print(result)\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
